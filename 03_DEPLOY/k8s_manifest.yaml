# Kubernetes Manifest for RAG System
---
apiVersion: v1
kind: Namespace
metadata:
  name: rag-system
  labels:
    name: rag-system
---
apiVersion: v1
kind: Secret
metadata:
  name: rag-secrets
  namespace: rag-system
type: Opaque
stringData:
  OPENAI_API_KEY: ""

---
apiVersion: v1
kind: ConfigMap
metadata:
  name: rag-config
  namespace: rag-system
data:
  VECTOR_DB_HOST: "chromadb-service"
  VECTOR_DB_PORT: "8000"
  LLM_API_HOST: "llm-api-service"
  LLM_API_PORT: "8000"
  CHROMA_DB_PATH: "/data"
  LOG_LEVEL: "info"

---
apiVersion: v1
kind: PersistentVolumeClaim
metadata:
  name: chromadb-pvc
  namespace: rag-system
spec:
  accessModes:
    - ReadWriteOnce
  resources:
    requests:
      storage: 10Gi
  storageClassName: standard

---
apiVersion: v1
kind: Service
metadata:
  name: chromadb-service
  namespace: rag-system
spec:
  selector:
    app: chromadb
  ports:
    - protocol: TCP
      port: 8000
      targetPort: 8000
  type: ClusterIP

---
apiVersion: apps/v1
kind: Deployment
metadata:
  name: chromadb
  namespace: rag-system
  labels:
    app: chromadb
spec:
  replicas: 1
  selector:
    matchLabels:
      app: chromadb
  template:
    metadata:
      labels:
        app: chromadb
    spec:
      # nodeSelector:
      #   nodepool-name: cpu1
      containers:
      - name: chromadb
        image: chromadb/chroma:latest
        ports:
        - containerPort: 8000
        env:
        - name: CHROMA_DB_PATH
          valueFrom:
            configMapKeyRef:
              name: rag-config
              key: CHROMA_DB_PATH
        volumeMounts:
        - name: chromadb-storage
          mountPath: /data
        resources:
          requests:
            memory: "4Gi"
            cpu: "2000m"
          limits:
            memory: "8Gi"
            cpu: "3000m"
        livenessProbe:
          httpGet:
            path: /api/v2/heartbeat
            port: 8000
          initialDelaySeconds: 30
          periodSeconds: 10
        readinessProbe:
          httpGet:
            path: /api/v2/heartbeat
            port: 8000
          initialDelaySeconds: 5
          periodSeconds: 5
      volumes:
      - name: chromadb-storage
        persistentVolumeClaim:
          claimName: chromadb-pvc

---
apiVersion: apps/v1
kind: Deployment
metadata:
  name: llm-api-gpu1
  namespace: rag-system
  labels:
    app: llm-api
    gpu-type: gpu1
spec:
  replicas: 2
  selector:
    matchLabels:
      app: llm-api
      gpu-type: gpu1
  template:
    metadata:
      labels:
        app: llm-api
        gpu-type: gpu1
    spec:
      # nodeSelector:
      #   nodepool-name: gpu1
      containers:
      - name: llm-api
        image: llm-api:latest
        imagePullPolicy: IfNotPresent
        ports:
        - containerPort: 8000
        env:
        - name: OPENAI_API_KEY
          valueFrom:
            secretKeyRef:
              name: rag-secrets
              key: OPENAI_API_KEY
        - name: LOG_LEVEL
          valueFrom:
            configMapKeyRef:
              name: rag-config
              key: LOG_LEVEL
        - name: GPU_TYPE
          value: "mig-3g.40gb"
        # resources:
        #   requests:
        #     memory: "8Gi"
        #     cpu: "4000m"
        #     nvidia.com/mig-3g.40gb: 1
        #   limits:
        #     memory: "16Gi"
        #     cpu: "6000m"
        #     nvidia.com/mig-3g.40gb: 1
        livenessProbe:
          httpGet:
            path: /health
            port: 8000
          initialDelaySeconds: 60
          periodSeconds: 30
        readinessProbe:
          httpGet:
            path: /health
            port: 8000
          initialDelaySeconds: 30
          periodSeconds: 10

---
apiVersion: apps/v1
kind: Deployment
metadata:
  name: llm-api-gpu2
  namespace: rag-system
  labels:
    app: llm-api
    gpu-type: gpu2
spec:
  replicas: 2
  selector:
    matchLabels:
      app: llm-api
      gpu-type: gpu2
  template:
    metadata:
      labels:
        app: llm-api
        gpu-type: gpu2
    spec:
      # nodeSelector:
      #   nodepool-name: gpu2
      containers:
      - name: llm-api
        image: llm-api:latest
        imagePullPolicy: IfNotPresent
        ports:
        - containerPort: 8000
        env:
        - name: OPENAI_API_KEY
          valueFrom:
            secretKeyRef:
              name: rag-secrets
              key: OPENAI_API_KEY
        - name: LOG_LEVEL
          valueFrom:
            configMapKeyRef:
              name: rag-config
              key: LOG_LEVEL
        - name: GPU_TYPE
          value: "mig-7g.80gb"
        # resources:
        #   requests:
        #     memory: "16Gi"
        #     cpu: "8000m"
        #     nvidia.com/mig-7g.80gb: 1
        #   limits:
        #     memory: "32Gi"
        #     cpu: "12000m"
        #     nvidia.com/mig-7g.80gb: 1
        livenessProbe:
          httpGet:
            path: /health
            port: 8000
          initialDelaySeconds: 60
          periodSeconds: 30
        readinessProbe:
          httpGet:
            path: /health
            port: 8000
          initialDelaySeconds: 30
          periodSeconds: 10

---
apiVersion: v1
kind: Service
metadata:
  name: llm-api-service
  namespace: rag-system
spec:
  selector:
    app: llm-api
  ports:
    - protocol: TCP
      port: 8000
      targetPort: 8000
  type: ClusterIP

---
apiVersion: apps/v1
kind: Deployment
metadata:
  name: rag-controller
  namespace: rag-system
  labels:
    app: rag-controller
spec:
  replicas: 3
  selector:
    matchLabels:
      app: rag-controller
  template:
    metadata:
      labels:
        app: rag-controller
    spec:
      # nodeSelector:
      #   nodepool-name: cpu1
      containers:
      - name: rag-controller
        image: rag-controller:latest
        imagePullPolicy: IfNotPresent
        ports:
        - containerPort: 8000
        env:
        - name: VECTOR_DB_HOST
          valueFrom:
            configMapKeyRef:
              name: rag-config
              key: VECTOR_DB_HOST
        - name: VECTOR_DB_PORT
          valueFrom:
            configMapKeyRef:
              name: rag-config
              key: VECTOR_DB_PORT
        - name: LLM_API_HOST
          valueFrom:
            configMapKeyRef:
              name: rag-config
              key: LLM_API_HOST
        - name: LLM_API_PORT
          valueFrom:
            configMapKeyRef:
              name: rag-config
              key: LLM_API_PORT
        - name: LOG_LEVEL
          valueFrom:
            configMapKeyRef:
              name: rag-config
              key: LOG_LEVEL
        # resources:
        #   requests:
        #     memory: "2Gi"
        #     cpu: "1000m"
        #   limits:
        #     memory: "4Gi"
        #     cpu: "2000m"
        livenessProbe:
          httpGet:
            path: /health
            port: 8000
          initialDelaySeconds: 30
          periodSeconds: 10
        readinessProbe:
          httpGet:
            path: /health
            port: 8000
          initialDelaySeconds: 10
          periodSeconds: 5

---
apiVersion: v1
kind: Service
metadata:
  name: rag-controller-service
  namespace: rag-system
spec:
  selector:
    app: rag-controller
  ports:
    - protocol: TCP
      port: 8000
      targetPort: 8000
  type: ClusterIP

---
apiVersion: networking.k8s.io/v1
kind: Ingress
metadata:
  name: rag-ingress
  namespace: rag-system
  annotations:
    nginx.ingress.kubernetes.io/rewrite-target: /
    nginx.ingress.kubernetes.io/ssl-redirect: "false"
spec:
  rules:
  - host: rag-system.local
    http:
      paths:
      - path: /api/rag
        pathType: Prefix
        backend:
          service:
            name: rag-controller-service
            port:
              number: 8000
      - path: /api/llm
        pathType: Prefix
        backend:
          service:
            name: llm-api-service
            port:
              number: 8000
      - path: /api/vector
        pathType: Prefix
        backend:
          service:
            name: chromadb-service
            port:
              number: 8000

---
apiVersion: batch/v1
kind: Job
metadata:
  name: rag-data-initialization
  namespace: rag-system
  labels:
    app: rag-data-init
spec:
  template:
    metadata:
      labels:
        app: rag-data-init
    spec:
      restartPolicy: OnFailure
      # nodeSelector:
      #   nodepool-name: cpu1
      containers:
      - name: rag-data-init
        image: rag-controller:latest
        imagePullPolicy: IfNotPresent
        command: ["python", "setting.py"]
        env:
        - name: VECTOR_DB_HOST
          valueFrom:
            configMapKeyRef:
              name: rag-config
              key: VECTOR_DB_HOST
        - name: VECTOR_DB_PORT
          valueFrom:
            configMapKeyRef:
              name: rag-config
              key: VECTOR_DB_PORT
        - name: LOG_LEVEL
          valueFrom:
            configMapKeyRef:
              name: rag-config
              key: LOG_LEVEL
        - name: LLM_API_HOST
          valueFrom:
            configMapKeyRef:
              name: rag-config
              key: LLM_API_HOST
        - name: LLM_API_PORT
          valueFrom:
            configMapKeyRef:
              name: rag-config
              key: LLM_API_PORT
        # resources:
        #   requests:
        #     memory: "1Gi"
        #     cpu: "500m"
        #   limits:
        #     memory: "2Gi"
        #     cpu: "1000m"
      initContainers:
      - name: wait-for-chromadb
        image: busybox:1.35
        command: ['sh', '-c', 'until nc -z chromadb-service 8000; do echo waiting for chromadb; sleep 2; done;']

---
apiVersion: autoscaling/v2
kind: HorizontalPodAutoscaler
metadata:
  name: rag-controller-hpa
  namespace: rag-system
spec:
  scaleTargetRef:
    apiVersion: apps/v1
    kind: Deployment
    name: rag-controller
  minReplicas: 3
  maxReplicas: 6
  metrics:
  - type: Resource
    resource:
      name: cpu
      target:
        type: Utilization
        averageUtilization: 70
  - type: Resource
    resource:
      name: memory
      target:
        type: Utilization
        averageUtilization: 80

---
apiVersion: autoscaling/v2
kind: HorizontalPodAutoscaler
metadata:
  name: llm-api-gpu1-hpa
  namespace: rag-system
spec:
  scaleTargetRef:
    apiVersion: apps/v1
    kind: Deployment
    name: llm-api-gpu1
  minReplicas: 1
  maxReplicas: 2
  metrics:
  - type: Resource
    resource:
      name: cpu
      target:
        type: Utilization
        averageUtilization: 70
  - type: Resource
    resource:
      name: memory
      target:
        type: Utilization
        averageUtilization: 75

---
apiVersion: autoscaling/v2
kind: HorizontalPodAutoscaler
metadata:
  name: llm-api-gpu2-hpa
  namespace: rag-system
spec:
  scaleTargetRef:
    apiVersion: apps/v1
    kind: Deployment
    name: llm-api-gpu2
  minReplicas: 1
  maxReplicas: 2
  metrics:
  - type: Resource
    resource:
      name: cpu
      target:
        type: Utilization
        averageUtilization: 70
  - type: Resource
    resource:
      name: memory
      target:
        type: Utilization
        averageUtilization: 75

