# 빠르게 AI 제품을 개선하는 실전 가이드


* 많은 AI 팀들이 **도구 선택에만 집중**하고 정작 중요한 **효과 측정과 반복 학습**을 간과함
* 저자는 30개 이상의 AI 제품 구축을 도와온 경험을 바탕으로, **성공하는 팀들의 공통된 실행 방식**을 소개
* 핵심은 **측정 중심 사고방식과 실험 기반 로드맵 구축**임

1. 가장 흔한 실수: 오류 분석 생략
---------------------

* 대부분의 AI 팀은 **아키텍처나 프레임워크 설계에 몰두**하고, 실제로 효과를 측정하지 않음
* **일반적인 대시보드 지표는 도움이 되지 않음**
  + 의미 없는 “허영 지표”에 집착
  + 너무 많은 지표로 팀의 집중력 분산
* **오류 분석은 ROI가 가장 높은 활동**
  + 실제 대화 로그를 열람
  + 실패 유형을 분류
  + 해당 문제에 대한 테스트 작성 및 개선 측정
* NurtureBoss 사례:
  + 날짜 처리 오류 해결
  + 정확도 33% → 95%로 개선
* **하향식(top-down)** 분석보다 **상향식(bottom-up)** 분석이 더 효과적
  + 실제 데이터를 기반으로 실패 패턴을 도출
  + 간단한 피벗 테이블로도 큰 통찰을 얻을 수 있음

2. 가장 중요한 AI 투자: 단순한 데이터 뷰어
---------------------------

* **팀이 실제 AI 출력을 쉽게 볼 수 있도록 하는 도구가 가장 중요**
  + 오픈 소스 툴보다 도메인에 맞춘 **맞춤형 인터페이스**가 효과적
  + NurtureBoss는 자체 데이터 뷰어를 통해 빠른 반복 개선을 가능하게 함
* 좋은 뷰어의 조건:
  + 전체 맥락을 한 화면에 표시
  + 피드백 수집을 쉽게
  + 오픈엔디드 주석 허용
  + 빠른 필터링 및 정렬
  + 단축키 지원으로 사용자 편의 향상
* FastHTML, MonsterUI 등으로 몇 시간 내 구축 가능
  + 단순한 스프레드시트부터 시작해도 좋음

3. 도메인 전문가에게 프롬프트 권한 부여
-----------------------

* AI 성능 개선은 오히려 **AI를 잘 모르는 전문가가 주도**할 때 효과적
* **프롬프트는 영어 문장**이므로 비전문가도 작성 가능
* 제품 UI에 “관리자 모드”로 **통합 프롬프트 환경**을 제공하면 반복 학습에 최적화
* 도메인 전문가와의 커뮤니케이션 팁:
  + 불필요한 기술 용어 제거
  + 예: “RAG 방식” → “AI가 질문에 답하기 위한 맥락을 확보함”
  + 팀 내 소통에서 **정확한 언어 사용**이 중요한 이유

4. 사용자 없이도 가능한: 합성 데이터로 부트스트랩
-----------------------------

* **사용자 데이터가 없어도 AI 평가 가능**
  + LLM이 합성 데이터를 생성할 수 있음
* 효과적인 합성 데이터를 위한 3가지 차원:
  + 기능 (예: 부동산 검색, 예약 등)
  + 시나리오 (예: 매칭 없음, 다수 매칭 등)
  + 페르소나 (예: 초보 구매자, 투자자 등)
* 실제 부동산 프로젝트 예시:
  + 시나리오별로 DB를 구성해 합성 쿼리 생성
  + LLM이 사용자 질문을 생성하고 시스템을 테스트
* 합성 데이터 작성 가이드:
  + 다양한 예제 생성
  + 입력 데이터 중심 생성
  + 시스템 제약 반영
  + 테스트 시나리오 유효성 검증
  + 단순한 케이스부터 점진적으로 확장

5. 평가 시스템에 대한 신뢰 유지
-------------------

* 많은 팀이 평가 시스템을 만들고 나중에는 **불신으로 인해 무시**함
* 평가 기준이 시간이 지나면서 **기준 이동(criteria drift)** 되는 것이 일반적
* 신뢰 유지를 위한 접근법:
  + **이진 평가(pass/fail)** 선호: 명확성과 일관성 확보
  + **상세한 크리틱 추가**: 정성적인 설명을 통해 맥락 제공
  + **자동 평가와 사람 평가의 정합성 측정**
    - 예: Honeycomb 프로젝트에서는 3회 반복 후 LLM 평가와 90% 이상 일치 달성
    - Eugene Yan의 AlignEval 도구 활용 가능
* 스케일 확장 전략:
  + 사람의 평가를 완전히 없애지 말고, **정보량 많은 샘플 위주로 집중**
  + 정기적으로 자동 평가와 사람 판단 비교하여 기준 재조정

6. 기능 중심이 아닌 실험 중심의 AI 로드맵
--------------------------

* 전통적인 “기능 중심 로드맵”은 AI에 적합하지 않음
* Hex의 전 AI 책임자 Bryan Bischof의 **“능력 퍼널(capability funnel)”** 접근법 제안
  + 예: 쿼리 어시스턴트의 퍼널
    1. 쿼리 문법만 맞춤
    2. 오류 없이 실행 가능
    3. 관련 결과 반환
    4. 의도와 일치
    5. 문제를 완전히 해결
* Eugene Yan의 실험 기반 일정 관리:
  + 데이터 가능성 검토 → 기술 가능성 검토 → 프로토타입 제작 → A/B 테스트
  + 실험의 결과를 경영진과 공유하며, 가능성 없으면 **초기 단계에서 전환 결정**
* 실패 공유 문화 조성:
  + 팀 내에서 “실패도 성과”로 공유
  + 반복과 실험을 장려하는 환경 형성

결론 및 핵심 원칙
----------

* 성공하는 AI 팀은 복잡한 도구보다 **측정, 반복, 학습**에 집중함
* 실천해야 할 6가지 원칙:
  1. **데이터를 직접 확인**하고 오류 분석 실행
  2. **간단하고 효율적인 도구** 제작으로 반복 학습 지원
  3. **도메인 전문가의 참여**를 유도하고 권한 부여
  4. **합성 데이터로 초기 평가 시스템 부트스트랩**
  5. **이진 평가 + 크리틱 + 정합성 체크로 신뢰 유지**
  6. **기능이 아닌 실험 수를 기준으로 로드맵 운영**
