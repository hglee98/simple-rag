# 최근 AI 모델 발전은 대부분 헛소리 같이 느껴짐


* 9개월전에 AI가 실제로 사람을 대체할 수 있을 정도로 **코드 보안 분석**을 잘 수행할 수 있다고 판단하여 스타트업을 설립함
* 초기에는 GPT-4o에서 Claude 3.5 sonnet으로 변경하자, 보안 취약점 설명과 심각도 판단에서 **질적으로 큰 향상**이 있었음
* 하지만 이후 Claude 3.6, 3.7을 포함한 대부분의 모델들은 내부 벤치마크나 버그 탐지 능력에 실질적인 개선을 보이지 않음
* 성능 향상은 주로 AI 모델 자체가 아닌 일반적인 엔지니어링 개선 덕분이었음
* 다른 스타트업들도 비슷한 경험을 했으며, 대부분 **새로운 모델 발표 → 벤치마크 상 좋은 성능 → 실제 성능은 미미함**의 사이클을 경험함
* 작성자는 **현재 AI 모델의 발전**이 경제적 유용성이나 일반화 능력에서 의미 있는 수준은 아니라고 판단함

AI 벤치마크와 실제 성능의 괴리
------------------

* AI 모델이 시험에서는 좋은 성적을 내지만, **실제 업무 능력에는 거의 반영되지 않음**
* 벤치마크는 주로 짧고 고립된 문제에 집중되어 있으며, 실제 응용에는 부적합함
* 예시로 Claude 모델은 Pokémon 게임을 끝내지 못할 정도로 장기 기억 유지가 어려움
* ‘Humanity’s Last Exam’ 같은 벤치마크는 언뜻 중요해 보이지만, \*\*실제 유용성을 제대로 평가하지 못함 \*\*
* 작성자는 앞으로 AI 성능을 판단할 때, Claude Plays Pokemon 같은 실제 사용 기반 벤치마크만 신뢰할 예정임

AI 연구소의 신뢰성 문제
--------------

* AI 연구소는 문명적 경쟁 속에 있으며, 일부는 성능을 과장하거나 **선택적으로 좋은 결과만 공개**할 유인이 있음
* 실제로 OpenAI, Anthropic 등이 사용하는 벤치마크는 대부분 공개된 테스트셋 기반으로 조작 가능성 존재
* ARC-AGI와 같은 반쯤 비공개된 평가 외에는 거의 모든 결과가 훈련된 데이터셋 기반일 가능성이 있음
* 가장 낙관적인 해석은, 문제가 기술적 한계가 아닌 인간의 부정행위라는 점임

벤치마크가 실제 유용성을 반영하지 못하는 구조적 이유
-----------------------------

* 인간의 IQ 테스트는 다양한 실제 성과와 상관관계를 가지지만, AI 벤치마크는 그렇지 않음
* AI 벤치마크는 대부분 **독립된 퍼즐**이나 **단기적 문제 해결 위주**로 구성되어 있음
* AI가 실제 문제에서 요구되는 기억, 상황 인식, 목표 추적 등에는 매우 취약함
* 벤치마크는 개발이나 평가에는 편리하지만, **현실에서의 총체적 능력과는 관련성이 낮음**

AI 모델이 똑똑하지만 정렬(alignment) 문제로 성능 제한 가능성
----------------------------------------

* 작성자의 회사는 실제 코드 보안 점검에 AI를 사용하는데, 모델은 **작업 맥락을 잘 이해하지 못함**
* 모델은 실제 서비스에 영향을 미치는 문제만 보고하라는 지침을 따르지 못하고, 불필요한 경고를 자주 출력함
* 이는 모델이 "**똑똑해 보이는**" 반응을 **선호하게 훈련**되었기 때문임
* 대화용으로는 괜찮지만, 시스템에 조합해 사용하려 하면 오류가 누적되어 문제로 이어짐
* 외형적 증상만 수정하려는 시도는 장기적으로 위험하며, 근본적인 정렬 문제 해결이 필요함

마무리 생각 및 사회적 함의
---------------

* 현재 AI가 과장된 기대에 비해 실제 성능은 떨어지며, 이는 많은 사용자의 ‘삶의 경험’과 일치함
* 정렬되지 않은 AI 시스템이 사회 전반에 영향을 미치기 전에, 더 근본적인 이해와 설계가 필요함
* 단순한 결과 중심의 벤치마크보다, **실제 사용 시나리오를 반영한 정성적 평가가 중요함**
