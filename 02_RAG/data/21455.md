# 자가 적응(Self-Adapting) 대형 언어 모델


* **기존의 대형 언어 모델(LLM)** 은 새로운 작업이나 지식에 맞게 즉각적으로 적응 능력이 부족함
* 새로운 **SEAL 프레임워크**는 LLM이 직접 자신의 미세조정 데이터와 업데이트 지침을 생성하여 자가 적응 기능을 가짐
* 이 과정은 **자가 편집(self-edit)** 생성, 지시 실행, 그리고 강화 학습(Based on RL) 루프를 통한 지속적 성능 개선 과정을 포함함
* SEAL은 **새로운 지식 통합** 및 **few-shot 일반화** 실험에서 기존 방법보다 향상된 성능을 입증함
* 본 연구는 **자가 지시적 적응** 능력을 갖춘 LLM 실현을 위한 유망한 발걸음을 제시함

---

개요
--

* **대형 언어 모델(LLM)** 은 강력한 성능을 보이지만, **자신의 가중치를 새 작업, 정보, 예시에 따라 동적으로 조정하는 메커니즘이 부재함**
* 본 논문은 **Self-Adapting LLM(SEAL)** 프레임워크를 제시하며, LLM이 자기 스스로 미세조정할 데이터를 생성하고 업데이트 지침을 만드는 것을 가능하게 함
* **SEAL**은 새로운 입력을 받으면, 모델이 정보를 다양한 방식으로 재구조화하거나, **최적화 하이퍼파라미터 지정**, 또는 **데이터 증강 및 그래디언트 기반 업데이트를 위한 도구 호출**과 같은 자가 편집(self-edit)을 생성함
* 이러한 자가 편집은 **지도 학습 미세조정(SFT)** 과정을 거쳐 모델의 가중치에 영구적인 업데이트로 이어지고, 지속적인 적응 능력을 보장함
* 효과적인 자가 편집 생성을 위해 **강화 학습 루프**를 활용하며, 모델 업데이트 후의 다운스트림 성능을 보상 신호로 사용함

인간 학습의 유추
---------

* **학생이 시험을 준비할 때 강의, 교과서, 인터넷 등에서 얻은 정보를 자기만의 방식으로 노트로 재작성하는 학습** 방식에서 영감을 얻음
* 사람마다 정보 재구성 방법이 달라서, 어떤 이는 도식, 어떤 이는 텍스트, 어떤 이는 수식 등으로 요약함
* 이는 외부 지식을 스스로 이해하기 쉽게 재조직하거나 보강하는 것이 인간 학습의 보편적 특징임
* 기존의 LLM은 새로운 작업이 주어지면, 주어진 데이터셋을 그대로 미세조정 혹은 인컨텍스트 학습만을 수행함
* 하지만 이러한 방식은 데이터 형식이나 양이 학습에 최적화되지 않은 한계가 있음

SEAL: 자가 적응 프레임워크의 제안
---------------------

* **SEAL은 LLM이 스스로 훈련 데이터 및 미세조정 지침을 자연어로 생성하도록 강화 학습 알고리듬으로 학습됨**
* 여기서 자가 편집(self-edit)은 데이터 및(선택적으로) **최적화 하이퍼파라미터**를 지정하는 명령어 형태임
* SEAL은 별도의 추가 모듈이나 보조 네트워크 없이, **모델의 자연어 생성 기능만으로 자신의 적응 프로세스를 직접 제어**함이 특징임

SEAL 작동 방식
----------

* 각 **강화 학습(RL) 외부 루프 반복(iteration)** 에서, 모델은 후보 자가 편집(SE)을 생성함
* 생성된 자가 편집을 적용하여 가중치를 업데이트함
* 이후 다운스트림 태스크에서 모델 성능을 평가하여, 해당 결과로부터 보상 신호를 획득함
* 보상 신호를 이용해 자가 편집 생성 정책을 반복적으로 개선함

실험 및 결과
-------

* **지식 통합 태스크**에서, SEAL은 모델이 직접 생성한 합성(synthetic) 데이터로 미세조정을 수행함
  + SQuAD의 no-passage-in-context 버전에서, RL 훈련 전 33.5%에서 RL 훈련 후 47.0%로 **질문-응답 성능**이 크게 향상됨
  + **SEAL이 생성한 데이터**는 GPT-4.1이 만든 합성 데이터보다도 더 우수한 성능을 보임
* **Few-shot 학습 실험**에서는 ARC-AGI 벤치마크의 단순화 버전을 사용하여, SEAL이 **증강 데이터와 최적화 하이퍼파라미터를 직접 선택**함
  + 학습률, 에폭, 토큰 유형별 선택적 손실 계산 등 다양한 도구 조합을 자동 선택
  + **강화 학습을 적용한 SEAL 사용 시 성능 향상**을 달성하며, 단순 인컨텍스트 학습이나 RL 없이 도구만 쓴 경우보다 효과적임

결론
--

* **SEAL 프레임워크는 자가 생성 데이터와 지침을 통한 LLM 자가 적응**이 가능함을 실험적으로 증명함
* 이 접근법은 향후 **데이터 효율성, 적응성 및 범용성**을 갖춘 차세대 언어 모델 개발을 위한 중요한 진전을 시사함
