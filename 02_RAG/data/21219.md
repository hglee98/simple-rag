# Valkey 1주년: 커뮤니티 포크가 Redis를 어떻게 추월했는가


* **Redis Inc**가 소스 폐쇄(SSPL 전환) 결정으로 커뮤니티 신뢰를 흔들었지만, **Valkey** 포크를 중심으로 개발자 커뮤니티가 결집해 활발한 혁신과 기여가 이어짐
* **Redis 8.0**은 다시 오픈소스로 돌아오고, 창시자 **Antirez**가 복귀해 새 기능과 최적화에 참여하는 등 양 진영 모두 빠른 발전을 보이고 있음
* 최신 벤치마크 결과, **Valkey 8.1.1**은 8vCPU 환경에서 SET 성능이 **Redis 8.0 대비 37% 더 높고**, p99 지연도 더 짧게 측정됨(GET 성능도 16% 우위)
* IO 스레드/코어 핀닝 등 실전 튜닝 기법으로, **Valkey는 멀티스레딩 환경에서 3배 이상 처리량 상승**과 지연 최소화를 실현
* 실사용 환경에 가까운 벤치마크 및 튜닝 노하우도 공유, 벤치마크 결과 해석시 유의점과 실제 운영 환경에서의 적용법도 안내

---

Redis 소스 폐쇄와 Valkey의 등장
-----------------------

* 1년 전 Redis Inc(구 Garantia Data)가 **오픈소스 라이선스 변경**(SSPL 도입)으로 커뮤니티와 신뢰관계가 악화됨
* 이에 대한 해결책으로 탄생한 오픈 포크 **Valkey**는 분산 시스템, 캐시, 실시간 데이터 처리 등에서 널리 사용되는 기술 자산이 됨
* Redis 측도 이후 **Antirez(창시자)** 복귀, 성능/기능 강화, Redis 8.0 오픈소스 재전환 등으로 신뢰 회복 시도

Valkey 8.1 vs Redis 8.0: 성능 비교
------------------------------

* 동일 8vCPU AWS c8g.2xl 인스턴스, 1KB 아이템/3M 키스페이스/500 커넥션 조건에서 SET 벤치마크
  + **Valkey 8.1.1**: **999.8K RPS**(p99 0.8ms)
  + **Redis 8.0**: **729.4K RPS**(p99 0.99ms)
  + **Valkey가 SET에서 37%, GET에서 16% 더 높고, SET p99 30%, GET p99 60% 더 빠름**
* 6개 IO 스레드 도입시, Valkey는 239K → 678K RPS(2.8배↑), p99 1.68ms → 0.93ms(44%↓)
* Redis도 IO 스레드로 235K → 563K RPS, p99 1.35ms → 0.84ms(40%↓)

멀티스레딩/코어 튜닝의 효과
---------------

* IO 스레드는 3개 이상부터 효과가 크게 나타나며, **Valkey는 4스레드 이후 Redis보다 큰 격차**
* IRQ(인터럽트) 코어를 2개로 제한 후, Redis/Valkey를 남은 6코어에 고정(pinning)하면 추가 성능상승
  + **Valkey: 832K → 999.8K RPS(코어/IRQ 핀닝, CPU 80% 활용)**
  + IRQ/애플리케이션 코어 분리로 캐시 효율과 tail latency 최소화
  + 실제 Docker로 cpuset-cpus, --io-threads 등 활용 예시 제공

벤치마크 재현과 실전 팁
-------------

* 최신 **AWS Graviton4(c8g.2xlarge)** 인스턴스, 클러스터 placement group 활용
* **코어 핀닝/IRQ 분리/연결수 조정**(400~500 선)로 최대 성능 구현
* **키스페이스/아이템 크기**도 튜닝 필요, 작은 값/키스페이스가 L3 캐시 적중률을 높임
* **valkey-benchmark**나 **rpc-perf**(실사용에 더 가까운 Rust 기반 툴) 등 멀티스레드 벤치마크 도구 적극 활용 권장

  ```
  docker run --network="host" --rm --cpuset-cpus="2-7" \  
  valkey/valkey:8.0.1 valkey-benchmark \  
  -h 172.31.4.92 -p 6379 -t SET,GET -n 100000000 -c 256 \  
  -r 3000000 --threads 6 -d 1024  

  ```

성능 측정의 한계와 유의점
--------------

* 벤치마크 결과는 실제 운영 환경과 다를 수 있음

  + 실제 워크로드는 SET:GET 혼합, 부하 변동, TPS 타깃, 네트워크 지연 등 복합 요인 존재
  + 연결수 급증 시 대기열 지연과 throughput 감소, tail latency 증가도 관찰됨
  + 벤치마크 툴/옵션, 네트워크 토폴로지 등에 따라 결과가 크게 달라질 수 있음

주요 성장과정 및 커뮤니티 발전
-----------------

Valkey 프로젝트는 지난 1년간 다양한 측면에서 활발한 발전을 이룸

* GitHub 등지에서 **많은 개발자와 기업의 협업** 하에 기능 추가, 버그 수정, 보안 개선 등을 이룸
* 문서화와 사용자 지원에도 힘써 **신규 사용자 진입 장벽을 낮춤**
* 프로젝트 운영 과정에서 **투명한 의사결정**과 **커뮤니티 투표** 등이 강조됨

업계와 기술적 가치
----------

Valkey는 다음과 같은 강점을 지님

* 라이선스 제약 없이 누구나 사용할 수 있어 **클라우드 서비스 벤더**나 **대규모 웹 서비스 기업**들에게 매력적인 선택지임
* Redis와 **호환성이 높아 마이그레이션도 용이**함
* 커뮤니티 주도 개발이어서 다양한 요구사항 반영과 빠른 지속적 업데이트가 가능함

결론 및 시사점
--------

* **Valkey**는 Redis 포크 1년만에 기술/성능/커뮤니티 측면에서 Redis를 뛰어넘는 성과를 보임
* IO 스레드, 코어/IRQ 분리, 커넥션 조절 등 실전 튜닝 노하우와 도구가 핵심
* 성능은 자동으로 따라오는 것이 아니며, 시스템/워크로드/인프라에 맞는 지속적인 최적화가 필수
* 실제 서비스 환경에서는 벤치마크 수치에만 의존하지 않고 다양한 상황을 직접 테스트하는 실무적 접근이 필요
