# 샤오미 MiMo 추론 모델


* MiMo-7B는 **언어 모델의 추론 잠재력**을 최대한 발휘하기 위해 개발된 모델 시리즈임
* **사전 훈련**과 **사후 훈련** 전략을 통해 수학 및 코드 추론 작업에서 뛰어난 성능을 발휘함
* MiMo-7B는 **작은 모델**임에도 불구하고 더 큰 모델과 **비교할 만한 성능**을 보임
* **오픈 소스**로 제공되어 커뮤니티에 기여할 수 있는 가능성을 가짐
* **RL 인프라**를 통해 훈련 및 검증 속도를 크게 향상시킴

---

I. 소개
-----

* 대부분의 성공적인 강화 학습(RL) 연구는 **큰 모델**에 의존하며, 작은 모델에서 수학 및 코드 능력을 동시에 향상시키는 것은 어려움
* MiMo-7B는 **추론 작업**을 위해 처음부터 훈련된 모델로, 더 큰 모델을 능가하는 **추론 잠재력**을 보유함
* MiMo-7B 시리즈는 **오픈 소스**로 제공되며, 커뮤니티에 강력한 추론 언어 모델을 개발하는 데 기여할 수 있음

🌟 주요 내용
-------

* **사전 훈련: 추론을 위한 기본 모델**

  + 데이터 전처리 파이프라인을 최적화하여 **추론 패턴 밀도**를 증가시킴
  + **다양한 합성 추론 데이터**를 생성하기 위한 여러 전략을 사용함
  + **다중 토큰 예측**을 추가적인 훈련 목표로 포함하여 모델 성능을 향상시킴
* **사후 훈련 레시피: 선구적인 추론 모델**

  + 130K의 수학 및 코드 문제를 RL 훈련 데이터로 사용함
  + **테스트 난이도 기반 코드 보상**을 도입하여 정책 최적화를 효과적으로 수행함
  + 쉬운 문제에 대한 **데이터 재샘플링 전략**을 구현하여 정책 업데이트를 안정화함
* **RL 인프라**

  + **Seamless Rollout Engine**을 개발하여 RL 훈련 및 검증을 가속화함
  + **MTP**를 vLLM에서 지원하고, RL 시스템의 추론 엔진의 견고성을 강화함

II. 모델 세부 사항
------------

* MiMo-7B 시리즈는 다양한 **모델 체크포인트**를 제공하며, HuggingFace에서 다운로드 가능함

III. 평가 결과
----------

* MiMo-7B-RL은 수학 및 코드 추론 작업에서 **우수한 성능**을 보임
* 다양한 벤치마크에서 **경쟁력 있는 결과**를 달성함

IV. 배포
------

* vLLM 및 HuggingFace를 통한 **추론 지원**
* **권장 환경** 및 프롬프트 사용을 통해 최적의 성능을 발휘할 수 있음

V. 인용
-----

* MiMo-7B에 대한 인용 정보 제공

VI. 연락처
-------

* 문의 사항은 **mimo@xiaomi.com**으로 연락하거나 GitHub 이슈를 통해 문의 가능함
