# OpenAI, Agents SDK에 MCP 지원 추가


* **MCP(Model Context Protocol)** 는 LLM에게 도구와 컨텍스트를 제공하는 표준화된 방식임
* USB-C 포트처럼, 다양한 데이터 소스나 도구와 AI 모델을 연결하는 표준 인터페이스 역할을 함
* OpenAI Agents SDK는 MCP를 지원하여 다양한 MCP 서버와 통합 가능함

MCP 서버
------

* 현재 MCP 사양은 사용하는 전송 메커니즘에 따라 두 가지 종류의 서버를 정의함:
  1. **stdio** 서버는 애플리케이션의 하위 프로세스로 실행되며, "로컬"에서 실행되는 것으로 생각할 수 있음.
  2. **HTTP over SSE** 서버는 원격으로 실행되며, URL을 통해 연결함.
* `MCPServerStdio`와 `MCPServerSse` 클래스를 사용하여 이러한 서버에 연결할 수 있음.
* 예를 들어, 공식 MCP 파일 시스템 서버를 사용하는 방법은 다음과 같음:

  ```
  async with MCPServerStdio(  
      params={  
          "command": "npx",  
          "args": ["-y", "@modelcontextprotocol/server-filesystem", samples_dir],  
      }  
  ) as server:  
      tools = await server.list_tools()  

  ```

캐싱
--

* 에이전트가 실행될 때마다 MCP 서버의 `list_tools()`를 호출하는 것은 지연 시간을 초래할 수 있음. 특히 서버가 원격 서버일 경우 더욱 그러함.
* 도구 목록을 자동으로 캐시하려면 `MCPServerStdio`와 `MCPServerSse`에 `cache_tools_list=True`를 전달할 수 있음. 도구 목록이 변경되지 않을 것이라고 확신할 때만 이를 수행해야 함.
* 캐시를 무효화하려면 서버에서 `invalidate_tools_cache()`를 호출할 수 있음.
