# 애플의 "추론 LLM의 한계" 논문에 대한 7가지 반박과 그 한계들 


* 애플의 **[생각의 환상: 추론 LLM의 한계 이해하기](https://news.hada.io/topic?id=21333)** 논문이 AI의 스케일링 가설에 문제를 제기하며 큰 반향을 일으킴
* 이에 대한 **대표적 반박 7가지**가 있었으나, 이 글의 저자 Gary Marcus(NYU 명예교수)는 모두 설득력이 떨어진다고 평가함
* **“인간도 실수한다”**, **“출력 길이 한계”, “논문 저자가 인턴”** 등 논점 흐리기, 본질 회피의 논거가 주를 이루고, 근본적 취약점 해결에는 미치지 못함
* “코드 사용으로 문제 해결” 등 일부 지적은 의미 있으나, **신경-기호 AI의 필요성**만 더 부각시킨다는 결론임
* 최근 SalesForce 연구 결과도 **실제 비즈니스 시나리오에서 LLM의 복잡한 멀티턴 추론 성능이 35%에 불과**함을 보여, 애플 논문의 우려와 일치함

---

애플 추론 논문 반박 7가지와 그 한계
---------------------

### 서론

* 애플의 **[Illusion of Thinking: 추론 LLM의 한계 이해하기](https://news.hada.io/topic?id=21333)** 논문은 **대형 언어 모델의 추론 및 알고리듬 수행 한계**를 드러내며 업계와 언론, 학계에서 큰 주목을 받음
* 글쓴이 Gary Marcus가 요약한 [논문 해설 포스트](https://open.substack.com/pub/garymarcus/p/a-knockout-blow-for-llms) 15만 명 이상이 읽었음
* *The Guardian*은 관련 포스트를 참조한 칼럼을 게재했고, ACM 및 프랑스어 버전도 등장해 글로벌한 관심을 증명함
* 이에 대해 GenAI 옹호자들이 논문에 비판적 반응을 보이고 여러 반박을 제기했으나, **모두 근본적인 반박이 되지 못함**

### 1. “인간도 복잡한 문제와 기억 요구에서 어려움을 겪는다”

* **인간도 어려워한다**는 주장 자체는 사실이지만, 애초에 컴퓨터·AI를 만든 이유는 **인간이 할 수 없는 계산·반복 작업을 정확히 처리**하기 위함
* 예시로, Tower of Hanoi 퍼즐에서 기존 **심볼릭 AI 시스템**은 오류 없이 수행 가능
* AGI라면 오히려 진보된 성능을 보여야 하며, 단순히 인간과 유사한 실수 범주에 머무는 것은 한계로 볼 수 있음
* **Apple 논문의 핵심**은 LLM이 복잡성과 학습 분포에서 멀어질수록 제대로 된 알고리듬 수행을 신뢰할 수 없음을 밝힘
* “인간도 실수한다”는 논점 흐리기임

### 2. “LRM은 출력 토큰 수 제한 때문에 풀 수 없다”

* LRM(대형 추론 모델)은 출력 길이 제한이 있으나, 사례 중 일부(예: 8개 디스크의 Hanoi, 255단계)는 충분히 출력 가능 범위임
* 잘 설계된 **심볼릭 AI**는 이런 문제의 영향을 받지 않으며, AGI 역시 마찬가지여야 함
* 토큰 한계는 버그이며, 해결책으로 볼 수 없음
* **기본적인 알고리듬도 신뢰성 있게 실행 못하면 현실 문제(군사 전략, 생물학 등)는 더더욱 불가능**

### 3. “논문 저자가 인턴이다”

* **Ad hominem(인신공격)** 에 해당, 본질과 무관. **과학적 관행을 무시한 오류**임
* 실제로 저자는 유망한 Ph.D. 학생이며, 논문에는 총 6명(4명은 Ph.D. 보유, Samy Bengio 등 저명 연구자 포함)
* **저자의 지위와는 별개로 논문의 품질이 핵심**

### 4. “더 큰 모델이면 잘할 수 있다”

* 일부 더 큰 모델에서 개선된 모습이 보고되나, 어떤 크기가 충분한지 예측도 불가
* 같은 구조의 LRM에서도 디스크 6개에는 성공, 8개에서는 실패하는 등 **일관되지 않은 결과**가 산출됨
* **모델 신뢰성과 예측 가능성 결여**, 항상 모든 문제에서 사전 검증 필요 → AGI와는 거리가 멂

### 5. “코드를 쓰면 문제를 풀 수 있다”

* 일부 LLM은 코드를 통해 문제를 해결 가능하나, 이는 **뉴로심볼릭 AI**의 장점임
* 진정한 의미의 AGI/AI라면 코드 없이도 개념적 이해 기반의 **추론 및 역추적**이 가능해야 함
* 시험이 학생의 개념 이해를 평가하듯, LLM도 진정한 **개념적 이해**가 필요한 상황임

### 6. “실험이 4개 예시뿐이고, 하노이 문제도 완벽하지 않다”

* 논문 내 4가지 예시 모두 완벽하지 않을 수 있으나, 다양한 선행 연구 결과와 일치하며, 유사 실패 사례는 계속해서 보고됨
* **NYU의 Tal Linzen** 등도 해당 맥락의 한계를 추가 증명함

### 7. “이미 다 아는 사실이다”

* 많은 연구자들은 오래전부터 LLM의 **일반화 취약성**을 인지하고 있었음
* 하지만 대중적·산업적 맥락에서 이번 논문으로 인해 **관심이 집중**되고 있음을 주목할 필요
  + 그간 과대평가/과장되어 왔던 AGI 가능성에 대해 업계가 **본격적으로 주목하고 논의하는 계기가 된 점이 중요**
* 연구자 사이에서도 “틀렸다”와 “이미 알던 사실”이 동시에 언급되는 **모순적 반응**이 나타남

### 결론

* 이상의 반박들 중 **결정적으로 설득력 있는 내용은 부족**함
* Apple 논문은 **스케일 확장이 AGI의 해답이 아니라는 분명한 신호**를 재차 제시함
* 현 LLM 기술은 신뢰성, 일반화, 개념적 추론에서 명확한 한계가 드러남
* 실제로 Sam Altman 등 주요 인물도 현재 상황을 심각하게 받아들이는 분위기 형성

SalesForce 논문과 추가적 수렴 증거
------------------------

### Holistic Assessment of LLM Agents Across Diverse Business Scenarios and Interactions

* SalesForce의 최신 논문에서 **실제 비즈니스 시나리오(고객 영업, 서비스, B2B/B2C 등) 기반 LLM 평가** 벤치마크 공개
* 단일턴(1회 질문-응답) 기준 **성공률 58%**, 멀티턴(연속 질의응답) 기준 **성공률 35%로 급락**
* 특히 **워크플로우 실행은 83% 이상 성과**를 내지만, 다중 추론/상황 전환 등에서는 한계
* **기밀성 인식(Confidentiality awareness)** 도 거의 없음, 프롬프트로 개선 가능하나 성능 저하 동반
* **실제 기업 환경의 복잡성·현실성 요구에 비해 LLM의 한계 명확**, 멀티턴 추론·기밀성·다양한 업무 스킬의 통합 필요성이 부각

요약
--

* 애플 논문과 SalesForce 논문 모두 **현세대 LLM이 실제 복잡한 추론, 멀티턴 대화, 알고리듬 수행 등에서 심각한 한계**를 드러냄
* AGI에 다가가기 위해서는 **스케일링을 넘어 신경-기호 통합, 구조적 개선**이 필요
* 업계와 연구자들이 본격적으로 한계 논의에 주목하기 시작한 것이 의미
