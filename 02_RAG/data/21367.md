# Cursor의 LLM 클라이언트 리버스 엔지니어링 하기 


* **TensorZero**를 오픈소스 프록시로 활용해, **Cursor와 LLM 제공자(OpenAI 등) 사이의 트래픽을 가로채 분석**하고, 프롬프트·모델·추론 결과를 실시간으로 관찰 및 최적화 실험한 경험 공유
* Cursor는 LLM 호출 시 **Base URL과 모델명을 오버라이드**할 수 있어, 자체 프록시(TensorZero)를 손쉽게 연동 가능
* 내부적으로 Cursor는 자체 서버를 거쳐 LLM을 호출하므로, 완전한 프록시 구성을 위해 **Ngrok + Nginx 리버스 프록시** 및 CORS 헤더 세팅이 필요함
* 프록시를 통해 **Cursor가 실제로 LLM에 보내는 system prompt, user prompt, 인라인 코드 편집 요청**까지 모두 관찰 가능하며, 다양한 LLM(A/B 테스트)로 실시간 전환/실험이 가능
* Cursor의 system prompt 분석 결과, **불과 642 토큰 정도의 프롬프트**만으로 대부분의 소프트웨어 엔지니어링 문맥을 LLM이 이해·처리함. 코드 편집은 별도의 "apply model"(덜 지능적인 보조 모델)이 담당
* TensorZero와 같은 프록시 구조로, **사용자별 맞춤형 LLM 실험 및 피드백 기반 최적화**가 가능하며, 이 구조는 코드 보조 도구의 품질 평가(A/B 테스트), 프롬프트 최적화, 실사용 모니터링에 이상적임

---

소개
--

* **TensorZero** 오픈소스 프레임워크를 Cursor와 각종 LLM(대형 언어 모델) 사이에 **프록시 게이트웨이**로 연결한 경험과 이로 인한 관찰, 실험, 최적화 지점을 다룸
* TensorZero는 **피드백 신호**(생산 지표, 사용자 행태 등)를 활용해 LLM 애플리케이션의 품질을 높일 수 있도록 도와주는 오픈소스임
* Cursor 사용자로서 가장 많이 쓰는 LLM 기반 IDE에 이 기술을 적용해, 실제로 어떤 API 요청이 오가는지, 그리고 어떻게 최적화를 직접 시도할 수 있는지 실험함

전체 개요 및 목적
----------

* **Cursor**는 사용자 전체를 기준으로 최적화된 코딩 어시스턴트이지만, **개인별 맞춤형 최적화 실험**과 데이터 관찰이 거의 불가능함
* TensorZero를 **프록시**로 두면, Cursor의 요청과 LLM 응답, 프롬프트, 모델, 인퍼런스 과정 전체를 투명하게 관찰하고, 실험하며, 최적화까지 확장 가능함
* 대부분의 **최적화 및 평가, 실험 방법**에는 실제 추론 데이터가 필수이므로, 이를 수집하는 실전 방법과 자동화 방식을 구체적으로 소개함

연동 과정: LLM 게이트웨이 구축
-------------------

* Cursor는 **OpenAI base URL**과 모델명을 사용자 정의로 변경할 수 있도록 지원함
* TensorZero는 **OpenAI 호환 인퍼런스 엔드포인트**를 제공하기 때문에, Cursor를 OpenAI 대신 TensorZero로 연결이 가능함
* TensorZero 내에 `cursorzero` 함수 등록을 통해, 다양한 모델/프롬프트 실험과 제공사에 종속되지 않는 **인퍼런스 및 피드백 데이터 자동화 저장**이 가능함

첫 번째 장애물: Cursor 자체 서버
----------------------

* Cursor가 **로컬 TensorZero**에 직접 연결을 시도했으나 실패함
* Cursor는 항상 우선 자체 서버에 요청을 보내고, 내부적으로 추가 처리 후 LLM 호출을 이어감
  + 이로 인해 **자격 증명**이 Cursor 서버로 전달되며, 해당 서버가 모든 요청 및 코드베이스에 대한 데이터 수집이 가능해짐
* 대안으로, **OpenRouter**로 연결하며 일부 Cursor 내 상호작용에서 외부 모델 이용 가능 여부를 점검함
* Cursor의 **Tab 자동완성**은 자체 비공개 모델로 동작, 다른 LLM과 조합 가능함
* 최종적으로 **reverse proxy**와 **Ngrok**을 활용, 외부 공개 엔드포인트를 통해 내부 TensorZero에 요청을 프록시하는 구조로 해결함
* **Nginx**를 앞단에 두어 인증 추가 및 보안 강화, 커스텀 TensorZero 함수로 LLM 라우팅까지 완료함
* 최종 구조:
  + Cursor → Ngrok → Nginx(인증) → TensorZero(로컬) → LLM Provider

두 번째 장애물: CORS
--------------

* 인증 시 **CORS preflight(OPTIONS)** 요청이 Nginx에 도달하며, 초기 인증 미수행 현상 발생
* Nginx에서 OpenAI API와 동일한 **CORS 헤더**를 반환하도록 설정하여, Electron 기반의 Cursor IDE 요구사항 충족함
* 인증 및 CORS 문제 해결 후, 모든 실제 요청은 Cursor 서버 경유로 이뤄짐
* (Nginx 설정 예시 코드 포함)

최종 결과: Cursor 들여다 보기 가능해짐
-------------------------

* **모든 LLM 요청/응답, system prompt, user prompt, 첨부 코드/파일 내용**을 실시간 관찰 가능
* system prompt 예시에는, 코드 편집용 별도 "apply model"을 구동하는 명령까지 명시됨 (이중 모델 계층 구조)
* Cursor 프롬프트의 주요 구조:
  + 사용자 세션 정보, 파일·커서 위치 등 맥락 제공
  + 코멘트 블록 등으로 구역 표시
  + 코드 수정 요청시에는 ‘변경 부분만 최소화’ 코드블록 생성 지침
* Cursor의 프롬프트 엔지니어링
  + 642토큰의 대형 시스템 프롬프트 하나만으로도 대다수 소프트웨어 엔지니어링 업무가 자동화됨
* 코드 변경 작업에 특화된 덜 지능적인 **apply model**(보조 모델)이 별도로 존재하며, 메인 LLM에 명확하게 적용 대상과 규칙을 지정
  + 다양한 LLM 계층 구조(지능, 기능 분리)가 실제 프롬프트 내부에 구현된 점을 확인함

결론 및 시사점
--------

* Cursor는 **최신 LLM의 기본 내장 지식과 간결한 프롬프트**만으로 소프트웨어 엔지니어링 문맥 처리가 가능
* TensorZero 등 프록시로 사용자별 피드백, 실사용 데이터 기반의 최적화(A/B 테스트, 프롬프트/모델 튜닝) 구조를 쉽게 구축할 수 있음
* 코드 에디터 보조 AI, LLM 도입 기업은 이 방식을 통해 **프롬프트 설계, 성능 개선, 사용자별 최적화**를 신속하게 실험할 수 있음
* 차기 글에서는 **실제 사용 데이터 수집 방식, 트리시터, git hook** 활용법 등 후속 실험을 할 예정
