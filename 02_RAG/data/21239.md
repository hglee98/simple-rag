# AI 답변에는 실수가 포함될 수 있음


* **AI 검색 요약**이 항상 정확하지 않음
* **PS/2 Model 280**에 대한 다양한 정보가 반복 조회 시마다 다르게 제공됨
* 존재하지 않는 **모델 번호도 그럴듯하게 설명**하는 AI의 환각 문제 발생
* 옳은 답변이 나오는 확률은 매우 낮은 수준임
* **비전문가**는 잘못된 정보를 쉽게 진실로 오해할 위험성이 높음

---

AI 검색 요약의 신뢰성 문제 경험
-------------------

### IBM PS/2 모델 검색 시도

* 1992년 출시된 **PS/2 Server** 시스템의 특정 모델을 찾으려 Google에 검색 진행
* 검색 결과로 나온 정보는 찾던 기계와 일치하지 않았으며, 원래의 모델은 **486 프로세서(복수형)** 와 **Microchannel(MCA)** 사용 특성이 있었음

### 반복된 결과와 답변의 불일치

* 동일 쿼리를 재실행했음에도 **AI 요약 결과가 매번 다르게 나타남**
* 예를 들어, 계속해서 **PS/2 Model 280**이 286 기반의 ISA 시스템이라는 주장을 반복함
* 각각의 답변에서 **RAM 용량 및 사양** 정보마저 바뀌어서 일관성 없는 데이터 제시 현상 확인

### 존재하지 않는 모델에 대한 환각적 설명

* 여러 번 질의한 결과, 286 시스템이 128MB까지 확장 가능하다는 주장 등, **기술적으로 불가능한 정보**도 생성됨
* PS/2 Model 280이 **IBM PC 라인업의 주요 발전**이었다는 설명까지 추가적으로 등장
* 실제로는 **PS/2 Model 280 자체가 존재하지 않음**에도, AI가 근거 없는 설명을 매우 그럴듯하게 제공함

### 올바른 답변의 낮은 빈도

* 여러 차례 쿼리 시도를 거친 후에야 간헐적으로 “Model 280은 실제 PS/2 시리즈 내 존재하지 않는다”는 올바른 답이 나옴
* **정확한 답변이 나타나는 비율은 매우 낮고** 대부분의 경우, AI는 근거 없는 정보를 창조함
* **환각된 답변은 정보로서 가치가 없으며** 오히려 잘못된 확신을 제공함

### AI 검색 요약의 맹신 경계

* **AI 기반 인터넷 검색**은 비전문가에게 매우 그럴듯하게 보일 수 있음
* 전문가라면 금세 실수를 간파하겠지만, **정보 확인 능력이 부족한 사용자** 입장에서는 허위 정보에 쉽게 현혹됨
* AI가 “실수를 할 수 있다”는 경고는 결코 가벼이 흘려들을 사안이 아니며, 신뢰할 수 있는 사실 확인 과정 없이 AI 답변에 의존하는 것은 위험함
* **설득력 있게 들린다고 해서 실제 사실에 기반하는 것은 아님**을 강조
* AI 기반 요약이나 검색 결과에 대해 항상 **의심과 사실 확인**의 필요성 상기
