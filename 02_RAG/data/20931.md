# 멀티 턴 대화에서 LLM은 길을 잃음 


* **대형 언어 모델(LLM)** 은 다중 턴 대화에서 **성능 저하**와 신뢰성 감소 현상을 보임
* 싱글 턴 대비 **다중 턴 상황**에서 평균 **39% 성능 하락**이 실험적으로 확인됨
* 주된 요인은 작은 **적성 감소**와 매우 큰 **신뢰성 저하**, 즉 결과의 일관성 부족임
* LLM은 이른 시점에서 **잘못된 가정**을 세우거나, **최종 해답**을 너무 빨리 시도하는 경향이 있음
* 결과적으로 LLM이 대화 초반에 실수하면 **회복하지 못하고 대화 방향을 잃는 현상**이 발견됨

---

ABSTRACT
--------

* **대형 언어 모델(LLM)** 은 대화형 인터페이스로, 사용자의 요구를 완전히 명시하지 못할 때에도 **다중 턴 대화**를 통해 점진적으로 요구 사항을 정의·탐색·수정하도록 도와줄 수 있는 잠재력을 가진 존재임
* 그러나 대부분의 LLM 평가가 **싱글 턴 완전 명세 지시** 환경에만 집중되어 있음에도, 실제 대화 로그 분석에서는 **지시 불명확(underspecification)** 현상이 빈번하게 보임
* 본 연구에서는 **싱글 턴**과 **다중 턴(underspecified)** 환경에서 LLM의 성능을 대규모로 시뮬레이션하여 비교함
* 그 결과, **15개의 주요 LLM** 모두에서 다중 턴 대화에서 평균 39%의 성능 저하가 있으며, 이는 **적성 약간 감소**와 **신뢰성 급격한 저하**로 분석됨
* LLM이 대화 초기에 잘못된 경로를 택할 경우 그 후에 **회복하지 못하고 방향을 잃고 헤맨다는 현상**이 포착됨

Introduction
------------

* 최신 LLM(예: ChatGPT, Gemini, Claude 등)은 **다중 턴 대화**가 가능한 인터페이스임
* 사용자가 처음부터 모든 요구를 명확하게 기술하지 않아도, 반복적인 질의응답(underspecified → refined)으로 점진적으로 요구를 구체화할 수 있음
* 실제 많은 사용자는 대화 초반에 불명확한 요구를 제시함에도, **대부분의 평가는 싱글 턴 완전 명세** 환경에서만 진행됨
* 일부 선행 연구는 다중 턴 평가를 시도하지만, 대화의 각 턴을 개별적인 에피소드로 취급하는 경우가 많으므로 실제 인간 대화에서 흔한 **불명확성**의 영향을 과소평가함
* 본 연구는 이 간극을 좁히고자, **sharded simulation**(정보를 여러 조각으로 나눠 각 턴마다 한 조각씩만 공개)이라는 환경을 제안해 다중 턴, 불명확 지시 상황을 정밀하게 시뮬레이션함

주요 연구 결과 요약
-----------

* 싱글 턴에서 LLM이 전체 지시를 한 번에 받을 때 **90%의 성능**을 보였으나, **다중 턴 불명확 지시**에선 **65%로 하락**(평균 25포인트 감소)
* 이 현상은 단 **두 번의 대화(turn)** 만 거쳐도 나타나며, 개방형·폐쇄형·대형·소형 모든 LLM에서 공통적으로 관찰됨
* **성능 저하**의 원인 분석 결과, (1) 적성 감소(aptitude loss)와 (2) **신뢰성(unreliability) 급증**임
  + 싱글 턴에선 적성 높은 모델이 신뢰성도 높게 나타났으나, 다중 턴에선 적성과 무관하게 신뢰성 낮음
  + 즉, LLM이 다중 턴 대화 중 잘못된 방향으로 접어들면 **회복 불가** — 이를 **“lost in conversation”** 현상으로 명명함
* 주된 원인
  + **장황한 응답** 및 **최종 해답 성급 시도**
  + **불명확 정보에 대한 잘못된 가정**
  + 이전의 잘못된 시도에 대한 과도한 의존
* 실제 LLM 활용 현장과 모델 평가 방식 사이에 **큰 간극** 존재함
  + 초보 사용자일수록 초반에 불완전한 지시를 내릴 때가 많아, 이 현상이 실전 적용을 어렵게 하는 주요 원인 중 하나
* 논문 구성 소개: 선행 연구 요약, 시뮬레이션 환경 설명, 6개 생성 작업 및 평가 지표, 15개 LLM 대규모 실험 및 결과, 그리고 실무·제품 적용 시사점 및 구체적 추천 사항 제시

Background and Related Work
---------------------------

* **과거 세대 언어 모델**(예: BART, GPT-2, T5)은 실제로 다중 턴 대화에 대응하지 못했기 때문에 **싱글 턴 위주**로 평가됨
* ChatGPT의 등장 이후 다중 턴 평가에 관심이 높아졌고, MT-bench 등 **크라우드 소싱 평가**가 이루어짐
* 하지만 대부분의 평가 체계가 **에피소드성 대화**(각 턴 개별 평가)에 머물러, 실제 불명확 대화의 연속성이 고려되지 않음
* 현실에서는 “최소 노력의 원칙”에 따라 인간이 불분명하게 지시(a.k.a. underspecification)하는 일이 흔하며, LLM도 **정보 부족 시 조기 결론 도출 및 적응 미비** 등으로 성능 저하
* 본 연구는 불명확성이 핵심인 실제 환경에 더 가까운 평가를 목표로 구성함

Simulating Underspecified, Multi-Turn Conversation
--------------------------------------------------

### 3.1 Sharding Process

* 원래의 **완전 명세 지시문**을 여러 **shard**(정보 조각)로 나눔
  + 예: 한 문장에 모든 조건을 담는 대신, 각 턴에서 하나의 정보(상황 설정, 수치, 조건 등)씩만 공개
* 첫 shard는 항상 **지시의 상위 목적**을 설명, 이후 shard가 추가 정보(문맥, 조건 등)를 턴마다 점진적으로 제공
* 이 **sharding** 과정은 LLM(GPT-4o) 제안+검증 및 수작업 보완으로 높은 품질의 다중 턴 지시 데이터 집합 구축
* 각 작업별로 90–120개의 sharded instruction 제작(수 시간 수작업 검수)

### 3.2 Simulating Sharded Conversations

* **대화 시뮬레이션**은 3자 역할: 평가 대상 LLM(assistant), 전체 shard를 아는 user simulator, 응답 분류 및 채점 시스템
* 첫 턴: user simulator가 첫 shard만 assistant에게 전달 → assistant가 응답 → 그 전략(명확화, 질문, 정답 시도 등) 분류 및 정답 추출 → 정답 평가
* 다음 턴: 남은 shard 중 한 개만 추가 공개하며 반복 / 각 턴마다 assistant가 자유롭게 응답
* **대화 종료**: (1) 평가자가 정답 판정하거나, (2) 더 제공할 shard가 없을 때
* user simulator는 LLM(GPT-4o-mini)로 구현되어, 자연스러운 shard 제공 및 자동 rephrase 능력을 가짐
* 전체 실험에서 보조 LLM의 오분류, 추출 오류는 5% 미만, assistant에 불리한 경우는 2% 미만
* assistant에게는 해당 환경에 대한 특별한 정보 없이 **디폴트 상태**로 평가(실전과 유사하게 시나리오 정보를 별도로 부여하지 않음)

### 3.3 Simulation Types

* **FULLY-SPECIFIED (FULL):** 싱글 턴에 전체 지시 제공, 베이스라인 성능 평가용
* **SHARDED:** 턴마다 한 개의 정보 조각만 공개, 다중 턴 불명확 대화 본 연구의 핵심 실험
* **CONCAT:** sharded instruction 전체를 한 번에 bullet-point로 제공, 지시 정보 손실만 평가
* **RECAP:** sharded 대화 후 마지막에 모든 shard 요약/재제공, simple agent-like 개입 시도의 한 형태
* **SNOWBALL:** 각 턴마다 새로운 shard 추가와 함께 이전에 공개한 shard 전체를 반복하여, assistant가 정보를 놓치지 않게 반복 상기(메모리 보강 실험용)

Task and Metric Selection
-------------------------

### 4.1 Task Selection

* **총 6개 작업:** 프로그래밍(Code), 데이터베이스(SQL 생성), API 함수 호출(Actions), 수학(Math), 표→텍스트(Data-to-Text), 질의응답형 요약(Summary)
  + 예시: Python 함수 작성, 자연어→SQL 질의 변환 등
* 각 작업별로 고품질 벤치마크에서 90~120개 지시문 선별, sharding 후 수작업 검증
* 6개 모두 프로그래밍/비프로그래밍을 망라하는 대표 성격이며, long context를 요구하는 Summary 등 다양한 시나리오 포함

### 4.2 Metric Selection

* **평가지표**
  + 평균 성능(P): 여러 시뮬레이션에서 얻은 평균 점수(0~100)
  + 적성(A90): 상위 10% simulation 결과 값(90th percentile, best-case)
  + 신뢰성(U90\_10): 상위 90%-하위 10% 점수 차이(결과 일관성/변동성 측정)
* 예: box-plot의 맨 위가 적성, 위-아래 범위가 신뢰성임
* 6개 작업 모두 일관성 있는 척도로 점수 집계(정답 여부/유사성/BLEU 등)
* 모든 실험 파라미터, 예시, 샘플링 등에 대한 자세한 방법 및 코드도 부록/Appendix에 수록

Simulation Scale and Parameters
-------------------------------

* 총 600개 instruction을 6개 작업에 대해 구축, FULL/CONCAT/SHARDED 시나리오 실험
* **15개의 LLM**(GPT-4, Claude, Gemini 등)에 대해 각 조합별 10번씩 시뮬레이션, **20만 회 이상** 실험 데이터 생성
* 모든 실험은 temperature 1(샘플링)로 진행, 추가 실험(7.2)에서는 temperature의 효과도 분석
* 이 거대한 시뮬레이션 데이터로 LLM의 **다중 턴 underspecified 대화 내 행동 양상 및 성능 저하**의 주요 원인과 유형 파악 가능

Lost in Conversation Experiment
-------------------------------

* 이후 본문에서는 실험 세팅, 개별 모델 결과, 성능 저하 원인 분석, 보완 기법(RECAP/SNOWBALL) 시도, 실무적 시사점·구체적 권고 순으로 상세 설명함
