# DeepSeek 추론 엔진 오픈소스를 향한 여정


* **DeepSeek 팀이 내부 추론 엔진(DeepSeek Inference Engine)을 오픈소스로 환원**하기 위한 계획을 공개함
* 기존의 추론 엔진은 vLLM 기반이며, DeepSeek-V3 및 R1 모델의 배포 수요 증가에 따라 공유를 고려중
* **기존 코드와 인프라 종속성, 유지보수 부담 등으로 전체 공개는 어려움**, 대신 **모듈화 및 기능 단위 기여 방식**으로 방향 전환
* 앞으로는 **오픈소스 커뮤니티와 긴밀히 협력하여, 성능 최적화와 재사용 가능한 기능을 공유**할 계획
* DeepSeek은 **추론 최적화 및 모델 출시 시 커뮤니티와의 Day-0 지원 동기화**에 적극 나설 것임

---

DeepSeek 추론 엔진 오픈소스를 향한 여정
--------------------------

### 오픈소스 위크의 반응과 후속 기여

* 최근 진행된 [Open Source Week](https://github.com/deepseek-ai/open-infra-index?tab=readme-ov-file#202502-open-source-week)에서 여러 라이브러리를 오픈소스로 공개
* 커뮤니티의 긍정적인 반응 속에서 **협업, 토론, 버그 수정 등이 활발히 이루어짐**
* 이를 계기로 **DeepSeek 내부 추론 엔진을 오픈소스로 공유하기로 결정**함

### 기반 기술

* DeepSeek의 학습 프레임워크는 **PyTorch** 기반
* 추론 엔진은 **vLLM 프로젝트**의 초기 포크를 기반으로 개발되었으며, DeepSeek 모델에 특화된 많은 커스터마이징 포함

### 오픈소스 전체 공개에 따른 현실적인 제약

* **코드베이스 차이**: 1년 이상 전의 vLLM 포크에서 시작되어 구조는 유사하지만 상당히 변경됨
* **내부 인프라 의존성**: 클러스터 관리 도구 등 DeepSeek 자체 인프라와 강하게 결합되어 있어 외부 활용이 어려움
* **유지보수 자원 부족**: 소규모 연구팀으로서 대규모 오픈소스 프로젝트를 지속적으로 관리할 여력이 부족

### 대안: 기존 오픈소스 프로젝트와의 협업

앞으로는 다음 방향으로 기여 예정:

* **모듈화된 기능 추출**: 독립적인 라이브러리로 재사용 가능한 구성요소를 나누어 기여
* **성능 최적화 공유**: 내부 구현의 성능 개선점과 설계 아이디어를 기존 오픈소스 프로젝트에 반영

### 커뮤니티를 향한 감사와 비전

* 오픈소스 커뮤니티의 존재가 없었다면 AGI 개발의 진전은 불가능했을 것
* 운영체제, 언어, ML 프레임워크, 추론 엔진 등 **AI 혁신의 근간은 오픈소스 생태계**
* DeepSeek은 커뮤니티와의 공조를 통해 **AGI의 혜택이 인류 전체에 기여할 수 있도록 지속적으로 노력할 것**

> [!NOTE]  
> 이 글은 **DeepSeek Inference Engine 코드베이스의 오픈소스화 전략**에 대한 안내임.  
> 향후 모델 공개와 관련해 DeepSeek은 **오픈소스 커뮤니티 및 하드웨어 파트너와의 협업을 계속 확대**할 예정임.  
> 특히 모델 출시 전, **추론 관련 기술을 사전 공유 및 정렬**함으로써 다양한 하드웨어 환경에서 Day-0부터 SOTA 지원이 가능하도록 생태계를 조율해 나갈 것임.

