# 로드맵: Lakehouse 시대의 Data 3.0


* 기업의 **데이터 인프라**는 기술 발전에 따라 함께 진화하며 새로운 제품과 서비스를 가능하게 하고 있음
* 데이터 인프라는 기존의 온프레미스 데이터 웨어하우스에서 클라우드 기반 데이터 웨어하우스 및 데이터 레이크로 발전해왔음
* 최근에는 AI의 급격한 발전과 함께 **데이터 레이크하우스**라는 새로운 아키텍처가 떠오르며 **Data 3.0 시대로 진입**하고 있음
* 레이크하우스는 분석 및 AI 워크로드 등 다양한 용도를 지원하는 **고성능, 상호운용 가능한 통합 플랫폼**으로, 기업 데이터 인프라의 핵심을 재구상
* 이로 인해 수십억 달러 규모의 새로운 데이터 인프라 기업들이 등장할 가능성이 높아지고 있음

레이크하우스 혁신의 배경
-------------

* 2019년부터 2024년까지 기업의 데이터 인프라 투자 규모는 약 1800억 달러에서 3500억 달러로 두 배 증가
* 기존의 데이터 웨어하우스와 데이터 레이크는 AI의 요구사항을 완전히 충족하지 못함
* AI 중심의 워크로드는 다음과 같은 요구사항을 가짐:
  + 구조화, 반구조화, 비정형 데이터를 모두 다루어야 함
  + 실시간, 멀티모달, 조합 가능한 데이터 처리가 가능해야 함
  + 기존 데이터베이스와 벡터 데이터베이스 간 상호운용성 필요
* 기업 고객의 수요 변화:
  + 데이터 중복 제거 요구
  + 데이터 거버넌스 복잡성 증가
  + 공급업체 종속 탈피 및 유연성 요구
  + AI에 적합한 솔루션 탐색의 어려움

오픈 테이블 포맷이 레이크하우스를 가능하게 함
-------------------------

* Delta Lake, Iceberg, Hudi 같은 **오픈 테이블 포맷(OTF)** 이 레이크하우스의 기반을 형성
* 주요 기능:
  + **ACID 트랜잭션 지원**: 데이터 정합성과 안정성 보장
  + **배치 및 스트리밍 처리 지원**
  + **스키마 및 파티션 유연성 제공**
  + **타임 트래블 기능**으로 이전 상태로 복원 가능
  + **확장 가능한 메타데이터 관리**

레이크하우스 패러다임의 등장
---------------

* 데이터 레이크하우스는 데이터 웨어하우스의 성능과 데이터 레이크의 유연성을 결합한 **새로운 아키텍처**
* AI 기반 애플리케이션, 실시간 분석, 기업 인텔리전스를 위한 **차세대 인프라**로 부상
* 주요 기업과 스타트업이 레이크하우스 전환을 서두르고 있으며, 이와 관련된 새로운 시장이 형성되고 있음

Thesis 1: AI 중심 수집 및 변환으로 지능형 실시간 파이프라인 구현
------------------------------------------

* 기존 ETL 도구는 AI 스케일에 비효율적
* Prefect, Windmill, dltHub 등은 코드 기반 데이터 파이프라인 및 오케스트레이션을 지원
* Tobiko 같은 도구는 SQL 자동화, 데이터 라인리지, 종속성 추적 등을 제공
* Anthropic의 Model Context Protocol(MCP)은 **AI 워크플로의 맥락 유지를 위한 표준화된 인터페이스** 제공
* Apache Kafka와 Flink는 실시간 모델 학습 및 추론에 필수적인 메시징 및 스트리밍 처리 기능 제공
* Chalk AI는 실시간 추론 플랫폼 제공으로 빠른 의사결정에 기여
* 메타데이터 계층은 AI 시대에 중요한 \*\*진실의 원천(source of truth)\*\*으로 부상

Thesis 2: 메타데이터 계층의 전략적 중요성 부각
------------------------------

* 메타데이터는 이제 단순한 정보가 아닌 **행동을 유도하는 중심 계층**
* Iceberg, Delta Lake, Hudi 등의 오픈 테이블 포맷이 메타데이터 혁신을 이끔
* Datastrato, Vakamo 등의 **레이크하우스 네이티브 카탈로그**가 등장
* Acryl Data의 DataHub는 인간과 AI 에이전트의 데이터 접근 및 거버넌스를 지원
* OpenHouse, Apache Amoro, Ryft 등은 메타데이터를 중심으로 한 **제어 플레인(Control Plane)** 제공
* Flarion.io, Greybeam 등은 스토리지 이외의 계층에서 **성능 최적화 도구** 개발 중

Thesis 3: 컴퓨팅 및 쿼리 엔진의 변화
-------------------------

* 레이크하우스의 확산으로 기존의 단일 플랫폼 중심 구조에서 **모듈형 아키텍처로 전환**
* Snowflake, Databricks 외에도 DuckDB, ClickHouse, Druid 등 특화된 솔루션 성장
* Daft, typedef, Mooncake, Bauplan 등은 AI 중심 최적화를 위한 새로운 컴퓨팅 프레임워크 개발 중
* AI에 최적화된 쿼리 엔진 및 연합 컴퓨트 플랫폼의 등장은 **데이터 처리의 새로운 기준**을 형성

Thesis 4: 데이터 엔지니어링과 소프트웨어 엔지니어링의 경계가 모호해짐
------------------------------------------

* AI 중심 애플리케이션은 **전체 개발자가 데이터 중심 역량을 갖추는 방향으로 변화**
* dbt Labs는 데이터 개발에 버전 관리, 테스트, CI/CD 등 소프트웨어 엔지니어링 관행을 도입
* Gable은 사용자 친화적인 인터페이스로 데이터 파이프라인 구축 지원
* Temporal, Inngest는 복잡한 분산 워크플로의 신뢰성과 가시성 확보
* 오픈 소스에 대한 기여가 급증하며 GitHub 데이터 관련 프로젝트의 성장률은 일반 소프트웨어보다 높음
* LLM의 지원을 잘 받기 위한 오픈 소스 채택 증가
* AI와 데이터 중심의 엔지니어링이 융합되면서 **팀 구조와 개발 방식이 근본적으로 변화**
