# 에이전틱 코딩에서 개발자 역량의 역할


* 에이전트형 코딩 어시스턴트가 더 유능해짐에 따라 반응은 매우 다양하고, 일부는 "**1년 안에 개발자가 더 이상 필요하지 않을 것**"이라고 주장
* 다른 사람들은 AI가 생성한 **코드의 품질**과 **주니어 개발자를 이러한 변화하는 환경에 대비시키는 방법**에 대해 우려를 제기함
* 지난 몇달간 Cursor, Windsurf, Cline 같은 에이전트형 코딩 도우미를 사용했고, 기존 코드베이스 변경에 매우 효과적임
* IDE 통합에 매우 감명받았고, 테스트 실행 및 자동 오류 수정, 린트/컴파일 오류 감지 및 수정, 웹 검색, 브라우저 프리뷰 기능까지 통합됨
* 개발자와 AI 간 협업 경험이 매우 인상적이며 빠른 문제 해결 및 기능 구현에 기여함

* 그러나 여전히 개발자의 지속적인 개입, 수정, 방향 설정이 필요했음
* 실제 커밋까지 이어지지 않은 경우도 많았으며, AI가 자율적으로 사소하지 않은 작업을 위한 코드를 작성하기에는 부족함
* 따라서 개발자의 기술과 경험은 여전히 중요하며, 앞으로도 지속적으로 훈련되어야 함

개발자가 직접 개입해야 했던 순간들
-------------------

* AI 도구들은 특정 영역에서 **항상 약한 성능**을 보였으며, 이는 반복적으로 확인됨
* 일부는 추가 프롬프트나 커스텀 룰로 **부분적으로 완화 가능**하지만 **완전한 제어는 불가능**
  + LLM은 프롬프트의 지시를 **정확히 따르지 않는 경우가 많음**
  + 코딩 세션이 길어질수록 **결과의 일관성이 떨어짐**
* 따라서 아래에서 소개하는 사례들은 **프롬프트나 설정과 무관하게 충분히 발생할 수 있는 이슈**
* AI 실수들을 **영향 반경**에 따라 3가지 범주로 분류
  + a. **개발 속도 및 커밋 시간 저하**
    - AI가 오히려 속도를 늦춤
    - 비보조 코딩보다 비효율적인 경우
  + b. **팀 작업 흐름에 마찰 유발**
    - 한 iteration 내에서의 충돌이나 협업 문제 발생
  + c. **장기적인 코드 유지보수성 저하**
    - 초기에는 문제 없어 보이지만, 향후 변경이나 확장 시 문제 발생
* **영향 반경이 클수록**, 팀이 해당 문제를 인지하고 수정하는 **피드백 루프가 길어짐**

영향 반경: 커밋까지의 시간 지연
------------------

* 이 범주는 AI가 **도움이 되기보다는 방해가 되었던** 사례들로 구성됨
* 가장 명확한 실패 형태이기 때문에 **크게 문제되지는 않음**
  + 대부분 커밋 전 단계에서 개발자가 문제를 인지하고 막을 수 있음
* 작동하지 않는 코드
  ----------

  + AI가 생성한 코드가 **기본적으로 작동하지 않음**
  + 개발자가 직접 수정하거나, AI 세션을 종료하고 **수작업으로 문제 해결** 필요
  + 경험 있는 개발자는 어디서 잘못되었는지를 **빠르게 판단하고 조치 가능**
* 문제의 잘못된 진단
  ----------

  + AI가 문제의 원인을 잘못 판단하고 **엉뚱한 방향으로 해결책을 시도**함
  + 과거 경험을 바탕으로, 개발자가 잘못된 경로에서 **AI를 끌어올 수 있었음**
    > *예시: Docker 빌드 오류를 아키텍처 설정 문제로 오해해 설정을 수정함*  
    > 실제 원인은 잘못된 아키텍처에서 빌드된 `node_modules` 복사였음  
    > 이전에 자주 겪은 문제였기 때문에 빠르게 인지하고 바로잡을 수 있었음

영향 반경: iteration 내 팀 작업 흐름
--------------------------

* 이 범주는 리뷰나 개발자의 개입 부족으로 인해 **iteration 기간 중 팀 내 마찰이 발생하는 경우**
* 저자는 과거 다양한 팀 경험 덕분에 이러한 문제를 **커밋 전에 사전에 인지하고 조정할 수 있었음**
* 신입 개발자들도 AI와 함께 시행착오를 겪으며 이러한 교훈을 얻어갈 수 있음
* 하지만 AI로 인해 **코딩 속도가 빨라지면**, 팀이 이 문제들을 **감당하지 못할 수 있음**
* 과도한 초기 작업
  ---------

  + AI는 점진적 구현보다는 전체 기능을 한 번에 넓게 처리하려는 경향 있음
  + 이로 인해 기술 선택이 부적절하거나 기능 요구사항을 잘못 이해했을 경우, **많은 작업이 낭비될 수 있음**
    > *예시: 프론트엔드 스택 마이그레이션 시, 전체 UI 컴포넌트를 한 번에 변환 시도*  
    > 백엔드와 통합되는 **하나의 컴포넌트부터 점진적으로 적용**했어야 함
* 원인 분석 없이 무작정 해결
  ---------------

  + AI가 문제의 **근본 원인을 분석하지 않고**, 단순히 외형적으로 보이는 오류를 해결하려는 방식 사용
  + 이후 문제를 맡게 된 다른 팀원이 **문맥 없이 문제를 다시 분석해야 하는 부담** 발생
    > *예시: Docker 빌드 중 메모리 오류 발생 시, 원인을 찾기보단 메모리 설정만 증가시킴*
* 개발자 워크플로우 복잡화
  -------------

  + AI가 생성한 빌드/실행 방식이 개발자 경험을 저하시킴
  + 즉시 커밋하면 **다른 팀원들의 워크플로우에도 악영향**
    > *예시: 프론트엔드와 백엔드를 각각 실행하는 명령어를 분리하여 제공함*  
    > *예시: hot reload 기능 누락*  
    > *예시: 복잡한 빌드 설정으로 개발자와 AI 모두 혼란스러움*  
    > *예시: Docker 오류를 사전에 감지하지 못하고, 빌드 후반에 오류를 처리하려 함*
* 잘못 이해되었거나 불완전한 요구사항
  -------------------

  + 기능 요구사항을 명확히 주지 않으면, AI가 **오해하고 엉뚱한 방향으로 기능을 구현**할 수 있음
  + 초반 개입으로 바로잡는 것이 이상적이나, 자율적인 AI나 생각 없는 개발자 모두에서 **후속 수정 비용이 증가**
  + 이러한 잘못된 구현은 나중에 스토리 진행 중 발견되어 **많은 수정 작업과 커뮤니케이션 비용**을 발생시킴

영향 반경: 장기적인 유지보수성 저하
--------------------

* 가장 **은밀하고 위험한 영향 반경**
  + 초기에는 코드가 문제없이 작동하지만, 나중에 **변경과 확장이 어려워짐**
* 이러한 문제는 **수 주에서 수 개월 후에야 발견되는 경우가 많음**
* 특히 이 영역은 필자의 **20년 이상의 개발 경험이 가장 크게 작용한 부분**
* 장황하고 중복된 테스트 코드
  ---------------

  + AI는 테스트 생성을 잘하지만, 다음과 같은 문제가 자주 발생함:
    - 기존 테스트에 통합하지 않고 **새로운 테스트 함수 생성**
    - 이미 커버된 부분까지 **과도하게 많은 assertion 추가**
  + 초보 개발자들이 오해할 수 있는 부분: **더 많은 테스트 ≠ 더 좋은 테스트**
  + 중복이 많아질수록 유지보수가 어려워지고, 코드 변경 시 **테스트 대량 실패** 가능성 증가
  + 커스텀 명령으로 완화 시도했지만, 여전히 자주 발생
* 재사용성 부족
  -------

  + AI가 작성한 코드는 종종 **모듈화가 부족**하여 재사용이 어려움
    > *예시: 이미 존재하는 UI 컴포넌트를 인식하지 못하고 중복 구현*  
    > *예시: CSS 클래스를 쓰지 않고 인라인 스타일을 남발*
* 과도하게 복잡하거나 장황한 코드
  -----------------

  + AI가 **필요 이상으로 많은 코드**를 생성하여 불필요한 부분을 수동으로 제거해야 하는 경우 많음
  + 이는 유지비용을 증가시키고, **변경 시 에러 가능성을 높임**
    > *예시: CSS 변경 시, 많은 중복 스타일을 일일이 삭제해야 함*  
    > *예시: JSON 데이터를 보여주기 위해 불필요하게 복잡한 웹 컴포넌트 생성*  
    > *예시: 리팩토링 과정에서 기존 의존성 주입 체인을 인식하지 못하고,  
    > 이미 주입된 값을 또 다른 매개변수로 전달하여 설계를 복잡하게 만듦*
    >
    > - `value = service_a.get_value(); ServiceB(service_a, value=value)` 형태

결론: AI가 모든 코드를 대신 작성할 수 있을까?
----------------------------

* 지금까지의 경험을 바탕으로 볼 때, **1년 안에 AI가 전체 코드의 90%를 자율적으로 작성하는 일은 현실적으로 불가능**
* 다만, **코드 작성 보조 역할**로서는 일부 팀과 코드베이스에서 **90% 보조 가능성 있음**
* 실제로 필자는 **15K LOC 규모의 중간 복잡도 프로젝트에서 약 80% 정도 AI 도움을 받고 있음**

### AI의 실수를 방지하기 위한 방법

* 개인 개발자 차원에서 할 수 있는 일
  --------------------

  + **AI가 생성한 코드를 항상 신중하게 리뷰**할 것
    - 수정할 부분이 없는 경우는 거의 없음
  + **AI 세션이 혼란스러울 경우 즉시 중단**
    - 프롬프트를 수정하거나, 아예 수작업으로 전환 ("수제 코딩"이라고도 부름)
  + **단시간에 기적처럼 완성된 "그럴듯한" 솔루션 경계**
    - 장기 유지보수 비용이 숨어 있을 수 있음
  + **[페어 프로그래밍](https://martinfowler.com/articles/exploring-gen-ai.html#memo-05) 실천**
    - 4개의 눈, 2개의 뇌가 더 나은 판단을 제공함
* 팀 및 조직 차원에서의 대응 전략
  ------------------

  + **기존의 코드 품질 모니터링 도구 적극 활용**
    - 예: Sonarqube, Codescene
    - AI 도구 사용 시 **코드 중복, 코드 냄새 등**을 더 면밀히 감시해야 함
  + **Pre-commit hook 및 IDE 통합 코드 리뷰 설정**
    - 개발 초기에 문제를 잡기 위한 shift-left 전략 강화
  + **좋은 코드 품질 습관 재정립**
    - 팀 내에서 AI 코드로 인해 발생한 문제 사례("Go-wrong 로그")를 주간 회고에서 공유
  + **커스텀 룰 적극 활용**
    - 대부분의 AI 도구는 프롬프트와 함께 전달되는 **규칙 세트 설정 가능**
    - 팀이 함께 룰셋을 개선하면서 AI의 실수를 줄일 수 있음
    - 단, 세션이 길어질수록 **룰 무시 가능성 증가**
  + **신뢰와 소통이 바탕이 된 팀 문화 조성**
    - AI 도입은 새로운 변화이며, **모두가 초보자**라는 사실을 인지해야 함
    - "AI 있으니까 더 빨리 해라" 식의 압박은 **품질 리스크를 증가**시킴
    - 심리적 안전감이 있는 팀은 **문제 공유와 학습이 더 활발히 일어남**
