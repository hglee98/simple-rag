# DeepSeek가 대규모에선 저렴하지만 로컬에서는 비싼 이유


* **DeepSeek-V3**와 같은 일부 AI 모델은 대규모 제공 시 저렴하고 빠르지만 **로컬 실행** 시에는 느리고 비쌈
* 그 이유는 **GPU 활용 효율**과 관련된 **throughput(처리량)과 latency(지연시간)** 의 근본적 트레이드오프에 있음
* **배치 크기**를 키우면 GPU가 효율적으로 동작하지만, 사용자는 토큰이 모일 때까지 대기해야 해 **지연시간 증가** 현상 발생
* **Mixture-of-Experts 구조**와 **딥 파이프라인**을 가진 모델은 높은 배치와 지연시간을 필요로 함
* 로컬 단일 사용자 환경에서는 **충분히 큰 배치 형성**이 어려워 성능 저하 및 비용 증가 문제 발생
* OpenAI, Anthropic 등은 아키텍처 자체의 효율화, 고도의 배치 전략, 또는 과도한 GPU 투입 등으로 빠른 응답을 구현

---

배치 인퍼런스와 GPU 효율
---------------

* GPU는 **대규모 행렬 곱셈(GEMM)** 에 최적화된 하드웨어임
* 여러 사용자의 토큰을 한 번에 묶어 큰 행렬로 배치 실행 시, **낮은 왕복 오버헤드와 메모리 효율**로 인해 처리량이 급격히 향상됨
* 인퍼런스 서버는 여러 요청의 토큰을 큐에 쌓고, 적당한 크기의 배치를 선정해 대규모 GEMM 연산을 수행함
* 이 과정에서 서버는 **배치 크기(throughput 증가)** 와 **대기 시간(latency 증가)** 간의 트레이드오프를 선택하게 됨

왜 일부 모델은 대형 배치에 최적화되어 있는가
-------------------------

### Mixture of Experts (MoE)와 배치

* **MoE 구조(DeepSeek-V3, GPT-4 추정)가 GPU 효율이 낮은 주요 원인**임
* 수백 개의 ‘전문가’ 블록들이 각각 분리된 행렬 곱셈을 요구하므로, 소규모 배치에서는 각 전문가가 할 일이 적어 효율이 떨어짐
* 많은 동시 요청이 있어야 모든 전문가를 충분히 활용 가능하므로, 서비스 수준에서는 대형 배치가 필수임
* **짧은 대기(윈도우 5ms)** 에는 전문가들이 빈번히 유휴 상태, **긴 대기(윈도우 200ms)** 에서는 고효율 최대화 가능

### 딥 파이프라인 모델의 배치 이슈

* **수백 계층의 대형 트랜스포머**는 여러 GPU에 레이어별로 분할(파이프라이닝)해 실행함
* 하나의 배치 내 토큰 수가 파이프라인 스텝보다 적을 경우 ‘파이프라인 버블’ 현상 발생, 이는 처리량 감소로 이어짐
* 이를 방지하려면 큰 배치(긴 대기)가 필수적이며, 이로 인해 **모델 응답 시간이 길어짐**

왜 큐를 항상 가득 채울 수 없는가
-------------------

* 이론상 많은 동시 트래픽으로 항상 큐를 채운다면 버블을 피할 것으로 보임
* 하지만, **트랜스포머 Attention 단계에서 행렬 크기(길이)가 모두 같아야 배치화 가능**하므로, 실무상 단일 큐로 완벽 동작 어려움
* 또한, FFN과 attention 단계를 분리할 경우 **메모리 오버헤드** 급증 및 데이터 이동 비효율 이슈 발생

요약 및 결론
-------

* **대형 배치 처리**는 GPU 비용 절감 및 처리량 향상에 필수지만, 사용자는 대기시간이 길어짐
* **Mixture-of-Experts, 대형 파이프라인 구조** 모델은 본질적으로 대기 기반 고효율 배치 환경에 최적화됨
* **로컬처럼 트래픽이 적은 환경**에서는 최적화된 대형 배치 구성이 불가하므로 GPU 효율 급감 및 실행 비용 상승 문제 발생
* **OpenAI, Anthropic 등은 빠른 응답성을 보여주는데, 그 이유는**
  + (1) MoE가 아닌 더 효율적인 구조일 수 있음
  + (2) 배치/파이프라인 최적화, 고도의 추론 트릭 적용
  + (3) 필요한 것 이상으로 많은 GPU를 투입해 속도를 사는 구조일 수 있음

추가: 프리필 배치와 본문 배치의 차이
---------------------

* 트랜스포머는 한 사용자 프롬프트의 **프리필**(긴 입력)도 배치 실행해 빠른 초기 인퍼런스가 가능함
* 그러나 본문에서 논의한 배치는 여러 사용자 요청의 **본격 토큰 생성 단계**에서 발생하는 처리량-지연 트레이드오프 배치임
* 프리필 배치는 본문에서 언급된 동시 대형 배치와 직접적 관련 없음

참고 사항
-----

* 실제 인퍼런스 시스템은 **지속적 배치(continuous batching)** 방식을 병행해 배치가 차면 즉시 실행함
* 그러나 근본적인 **throughput-latency 트레이드오프** 구조는 동일하게 적용됨
