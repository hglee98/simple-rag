# AI 코드 리뷰: 작성자가 리뷰어가 되어도 될까?


* **AI가 작성한 코드**를 **AI가 리뷰**하는 것이 타당한지에 대한 흥미로운 질문
* Devin AI와 같은 봇이 **가장 많은 PR을 작성**하고 있으며, 리뷰 역시 AI가 수행되는 사례가 늘고 있음
* LLM은 **상태가 없고(stateless)**, **리뷰와 작성 시 내부 구조가 다르므로 역할 구분이 가능**하다는 주장도 존재함
* **AI가 생성한 코드는 사람보다 다른 유형의 버그를 유발**하고, AI는 **그 버그를 찾는 데 더 효과적**임
* 결과적으로 AI 리뷰는 인간 리뷰보다 **실제적인 오류 감지에 유리**, 단 인간의 건축적 판단과 스타일 가이드는 여전히 중요함

---

AI가 자기 코드를 리뷰해도 될까?
-------------------

* 대부분의 회사는 **작성자 ≠ 리뷰어** 원칙을 지키고 있음
* 그러나 AI는 LLM 기반으로 **상태가 없고 요청마다 새롭게 판단**함
* 즉, 동일한 엔진을 사용해도 **작성과 리뷰는 다른 “차”** 로 볼 수 있음

Scaffolding: AI 리뷰의 구조
----------------------

* 리뷰를 위한 AI는 다음과 같은 **특정 워크플로우**를 수행함:
  + 코드 diff 분석
  + 버그 감지
  + 코멘트 작성 및 심각도 판단
  + 코드베이스 문서와 연관 파일 참조
* 반면 코드 생성 AI는 **완전히 다른 맥락에서 동작**하므로 **리뷰와 생성은 기능적으로 다름**

인간도 사실은 "같은 엔진"
---------------

* PR 작성자와 리뷰어가 달라도, **같은 인간 지능**에서 나옴
* 같은 회사, 같은 훈련을 받은 **비슷한 지식과 경험**을 공유하고 있음
* 결국 AI와 인간 모두 **“동일 엔진, 다른 케이스”** 라는 점에서 유사함

AI 코드, 더 정밀한 리뷰가 필요함
--------------------

* AI 코드의 품질은 살짝 낮음
  ----------------

  + AI는 속도는 빠르지만, **프롬프트의 한계**로 인해 요건 전달이 부정확함
  + 좋은 개발자조차 AI 코드에 대해 **자신의 코드만큼 꼼꼼히 리뷰하지 않음**
  + 결과적으로 **전체 품질은 하향 평준화**되며, 중간 수준에 수렴함
* AI 버그는 사람이 찾기 어려움
  -----------------

  + AI가 만드는 버그는 **인간이 보통 만들지 않는 유형**
  + 예: 예상치 못한 라인 수정, 미세한 조건문 오류 등
  + Greptile 내부 테스트에 따르면:
    - **AI(Sonnet)** 는 “Hard” 버그 209개 중 32개 발견
    - **사람 개발자**는 평균 5~7개만 찾음

결론
--

* AI가 자기 코드를 리뷰하는 것이 **기술적으로는 가능하고 의미 있음**
* AI는 **버그 탐지에 인간보다 뛰어나며**, 리뷰에 실제로 유용함
* 그러나 인간의 **의도 해석, 설계 판단, 코드 스타일 판단**은 여전히 중요
* 작성자 ≠ 리뷰어라는 전통적 기준을 AI에게는 **새롭게 해석할 필요가 있음**
