# DeepSeek의 분산 파일 시스템 3FS 소개


* **3FS는 DeepSeek가 개발한 고성능 오픈소스 분산 파일 시스템**으로, 대규모 데이터 처리와 높은 처리량을 지원함
* **일반적인 파일 시스템처럼 동작하지만**, 실제로는 여러 머신에 데이터를 분산 저장하며 사용자는 이를 의식하지 않아도 되는 추상화 구조를 가짐
* **4가지 주요 구성 요소 (Meta, Mgmtd, Storage, Client)** 를 통해 메타데이터, 노드 관리, 실제 데이터 저장, 사용자 요청 처리 등을 분리하여 운영함
* **CRAQ 알고리듬을 통해 강한 일관성과 장애 허용을 달성**하며, 체인 구조로 쓰기 요청을 안전하게 전파함
* **3FS**는 다른 분산 파일 시스템과 비교하여 **실제 적용 가능성**과 **성능 확장성**에서 차별화됨

---

3FS란?
-----

* 3FS는 **Fire-Flyer File System**의 약자로, **DeepSeek**에서 공개한 **분산 파일 시스템**
* DeepSeek의 오픈소스 공개 주간에 함께 릴리즈됨
* 일반적인 파일 경로처럼 보이지만, 실제로는 여러 머신에 분산 저장된 데이터를 추상화해 제공함

분산 파일 시스템이란?
------------

* 사용자에게는 **로컬 파일 시스템처럼 보이지만**, 실제로는 여러 서버에 데이터를 분산 저장함
* 예: `/3fs/stage/notes.txt` 경로가 하나의 파일처럼 보이지만 실제론 여러 서버에 나뉘어 저장됨
* 사용자는 `mkdir`, `cat` 같은 명령어로 일반 파일처럼 사용할 수 있음

왜 분산 파일 시스템을 사용하는가?
-------------------

* **대용량 데이터 (페타바이트 수준)** 와 **높은 처리량**을 지원
* **장애 허용(fault tolerance)** 과 **중복성(redundancy)** 을 통해 안정성 보장
* 실제 사용 예:
  + **HDFS + Spark** 같은 병렬 처리 프레임워크
  + **ML 학습 파이프라인**의 체크포인팅
  + Google의 **Colossus**
  + Meta의 사진 저장소인 **Haystack**
  + AI용 스토리지 예: **JuiceFS vs CephFS**

3FS 구성 요소
---------

* 총 4가지 주요 노드로 구성됨

### Meta

* 파일 경로, 속성, 위치 등의 **메타데이터 관리**
* RPC로 클라이언트 요청 처리 (open, stat, close 등)
* 메타 정보는 **FoundationDB**에 저장됨
* `Inode`는 파일의 크기, 소유자 등의 정보를 저장
* `DirEntry`는 경로와 inode를 연결함 (심볼릭 링크처럼 하나의 파일에 여러 경로 존재 가능)

### Mgmtd

* 클러스터의 **노드 등록 및 상태 확인** 담당
* 노드들은 부팅 시 자신을 등록하고 주기적으로 **하트비트 전송**
* **중앙 라우터 역할**을 하며, 노드 간 연결을 직접 유지하지 않아도 됨
* CRAQ 체인 구성을 위한 설정 정보도 관리

### Storage

* 실제 데이터 저장 담당
* **Rust 기반의 ChunkEngine**을 통해 디스크 블록을 관리
  + 디스크 블록의 크기, 오프셋, 체크섬, 버전 등을 추적
  + 사용자는 직접 블록과 상호작용하지 않고 인터페이스 제공
  + 메타 정보는 **LevelDB**에 저장
* 다양한 워커들이 존재
  + `AllocateWorker`는 새 블록 할당
  + `PunchHoleWorker`는 사용되지 않는 블록 회수
  + `AioReadWorker`는 `io_uring` 큐를 통해 비동기 읽기 처리
* 쓰기 작업 시 CRAQ 체인을 따라 **다음 노드로 전달**

### Client

* 사용자 요청을 처리하고 다른 노드와 통신
* 작업 흐름:
  + Mgmtd에 노드 위치 질의
  + Meta에 파일 작업 요청
  + Storage와 데이터 전송

CRAQ 알고리듬
---------

* **Chain Replication with Apportioned Queries**의 약자로 **강한 일관성(linearizability)** 제공
* 쓰기 흐름:
  + Head → Middle → Tail 순으로 **쓰기 전파**
  + 중간 단계에서는 데이터를 **dirty**로 표시 (읽기 불가)
  + Tail에서 커밋 후 backward로 clean 상태 전파
* 읽기 흐름:
  + clean이면 즉시 반환
  + dirty이면 tail에 요청하여 최신 데이터 조회

### 성능 측면에서 CRAQ

* **쓰기 속도는 가장 느린 노드에 의해 제한**
* 자주 접근되는 dirty 데이터는 tail로 읽기 요청이 몰려 **읽기 병목 발생 가능**
* 예: **Zipfian workload**에서 성능 저하
* 노드가 5개인 클러스터에서는 3개로 복제하여 장애 시 성능 손실 최소화

다른 분산 파일 시스템과의 차이점
------------------

* 구조는 유사하지만 **현실 적용성과 구현 방식에서 차별점** 존재
* 비교 요소:
  + 어떤 워크로드에서 강점을 가지는지
  + 성능 조절의 유연성
  + 배포의 용이성
  + 처리량 확장성
  + SLO 내에서의 지연시간 관리
  + 신뢰성
* 세부 기술 요소:
  + 병목 원인과 처리 방식
  + 락의 유무
  + 사용된 자료구조
  + 타겟 하드웨어
  + 사용된 **장애 허용 알고리듬** 또는 **에러 정정 방식**

블로그 시리즈의 다음 주제
--------------

* 실제 성능 분석을 통해 DeepSeek의 주장 검증 예정
* 검토 항목:
  + **FUSE 병목**에 대한 DeepSeek의 주장
  + 성능 그래프 재현 가능성
  + 성능 저하 상황 분석
  + 병목 요소 (CPU, 메모리, 디스크, 네트워크)
  + 어떤 워크로드에서 성능이 우수한지
  + 기존 시스템과 비교 분석
  + 기존 시스템의 문제 해결 방식과의 차이
  + 직접적인 개선 가능성 검토

추가 자료
-----

* 공식 [디자인 노트](https://github.com/deepseek-ai/3FS/blob/ee9a5cee0a85c64f4797bf380257350ca1becd36/docs/design_notes.md)에서 구현 방식 참고 가능
* 중국어 문서:
  + [시작 가이드](https://www.high-flyer.cn/blog/3fs/)
  + [비동기 IO](https://www.high-flyer.cn/blog/3fs-1/)
  + [RDMA 읽기](https://www.high-flyer.cn/blog/3fs-3/)
  + [네트워크 라우팅](https://www.high-flyer.cn/blog/3fs-3/)
  + [읽기 부하 분산](https://www.high-flyer.cn/blog/3fs-4/)
* 논문 자료: [Fire-Flyer AI-HPC 아키텍처](https://arxiv.org/abs/2408.14158)
