# 저는 과학을 위한 AI의 과장된 광고에 속았습니다. 이게 제가 배운것들 입니다


* **플라즈마 물리학 연구에서 AI 활용**에 대한 기대와는 달리, 실제 적용 결과는 **과장된 성과 및 한계** 중심임
* AI를 이용한 PDE(편미분방정식) 풀이 방식(PINN 등)은 **신뢰성과 성능** 면에서 기존 수치적 방법보다 확실한 우위 제공 미비함
* **약한 비교 기준(weak baseline)** 과 **보고 편향** 때문에 AI 성과에 대한 논문 대부분이 실제보다 과도하게 긍정적인 평가임
* AI의 과학적 활용이 급증하고 있으나, **과학 진보 혁신을 주도하는 도구**라기보다 **점진적·제한적 기여** 가능성에 무게 둠
* 과학 논문 구조 및 연구자 인센티브 탓에 **실패 사례 미공개·과장 보고**가 반복되며, AI의 과학적 영향 평가 시 **본질적 회의적 시각** 필요성 강조함

---

서론 및 연구 배경
----------

* 필자 Nick McGreivy는 Princeton에서 플라즈마 물리학으로 박사 학위를 취득한 후, AI가 과학 연구(특히 물리학) 혁신에 기여할 수 있다는 기대감으로 머신러닝 활용 연구로 전향함
* AI가 **일렉트로닉스, 인터넷, 집적회로** 등과 같은 범용 기술처럼 과학 전반을 획기적으로 바꿀 수 있을지에 관심을 가짐
* 실제로는, **AI를 활용한 PDE(편미분방정식) 풀이** 연구에서 유명 논문의 발표된 성과 대비, 실제 적용 시 기대 이하의 결과 경험

PINN(Physics-Informed Neural Network) 적용 경험
-------------------------------------------

* AI를 이용한 PDE 풀이 분야에서 **PINN**이 대표적 방법으로 급부상하였고, 필자 또한 이 방식을 실험적으로 시도함
* 기존 논문에서는 PINN이 고전 유체, 양자역학, 반응-확산 시스템 등 다양한 분야 PDE 문제에서 **효과적 솔루션**을 제공했다고 보고했으나, 실제로는 **아주 간단한 PDE(1D Vlasov 등)에도 불안정하거나 신뢰성이 크게 떨어지는 결과** 경험
* 간단한 튜닝으로 개선이 어렵고, 복잡한 PDE(1D Vlasov-Poisson 등)에서는 아예 적절한 해 도출 실패함
* 주변 연구자들도 유사한 실패를 경험하였으나, 이러한 **부정적 결과는 거의 논문으로 발표되지 않음**

PINN 실험을 통한 교훈
--------------

* 영향력 있는 1차 논문 저자조차 특정 셋팅에서는 PINN이 실패함을 인지했으나, 설득력 있는 결과만 공개함
* 과학 논문 생태계에서 **긍정적 결과 위주 보고**와 AI 관련 실패 실험 미공개 관행은 **생존자 편향(survivorship bias)** 심화 요인임
* PINN 방식은 수치적으로 아름다운 개념이지만, **불안정성·미세조정 난이도·처리 속도 저하** 등 실용적 한계로 인해 선택을 포기한 경험 공유함
* 원 논문은 14,000회 이상의 인용을 받으며 수치 방법 분야 최고 인용 논문이나, 실제 PDE 풀이에선 기존 방법 대비 경쟁 우위 없음
* 최근에는 PINN이 **역문제(inverse problems)** 등 특정 영역에서 효과를 발휘할 수 있다는 주장도 있으나, 이에 대한 연구자 간 논쟁 존재

부적절한 비교 기준이 유발한 과잉 낙관
---------------------

* 필자는 이후, **전통적 수치 기법과 마찬가지로 PDE 해를 격자나 그래프 픽셀 집합으로 취급하는** 딥러닝 접근법을 시도함
* 여러 논문에서 AI로 PDE를 **기존 방법보다 최대 수천~수만 배 빠르게 해결**한다고 발표하였으나, 실제로는 **비교 기준으로 삼은 베이스라인(기준) 자체가 약한 방식**에 불과한 경우가 대다수임
* 대표 논문 분석 결과, AI가 강점을 보인다는 76편 중 60편(79%)은 충분히 성능 좋은 기존 수치 방법과 공정하게 비교하지 않은 것으로 판명됨
* 이 같은 약한 비교 기준과 **네거티브 결과 비공개**로 인해 "AI가 혁신적 성과"라는 평가는 실제보다 과장된 경향 확인됨
* 관련 연구 결과는 학계와 산업 전반에 논란을 일으켰으며, 일부는 **미래 연구 방향성** 및 AI의 잠재력 강화를 주장, 일부는 **현재 과대평가 문제 경계 심화** 표명

과학에서 AI의 역할 및 한계
----------------

* 대표적 성공 예는 **AlphaFold의 단백질 접힘 예측**, 기상 예보(예측 정확도 최대 20% 향상), 신약개발(임상 1상 성공률 상승) 등이 있으나, 광범위한 혁신보다는 **기존 기술 대비 보완적·점진적 진전** 위주임
* 글로벌 빅테크나 언론, 학계 등은 AI의 "과학 혁신적 도구" 내지는 "**과학 패러다임을 바꿀 변혁의 주역**"으로 포장하지만, **현재 수준 AI로는 기대만큼의 본질적 혁신 한계** 명확히 존재

AI 채택 동기와 연구 생태계의 구조적 문제
------------------------

* 과학자들이 AI를 도입하는 주된 이유는 **과학 자체 발전**보다는 개인적 성과(더 높은 연봉, 경력, 논문 인용, 연구 자금 유치 등) 때문임
* 실제로 AI 이용 연구자가 **상위 인용 논문 및 연구 경쟁력** 면에서 일반 과학자 대비 유리한 환경 제공 받는 현상 확인
* AI 활용 연구자는 "해결할 과학 과제"를 정의하기보다는, 애초에 "AI로 풀 수 있는 과제를 뒤에서부터 찾아가는" 구조적 함정 노출
* 이로 인해, **실제 과학 발전보다는 AI의 잠재력 시연에 집중**, 이미 해결된 문제나 부수적 효과만 도출하는 경우 많음

논문 보고의 구조적 한계와 과학 내 낙관 편향
-------------------------

* 부정적 결과의 미보고(생존자 편향)로 인해, **AI 활용 성공 사례**만 쏟아지고 실패는 공개되지 않아, 전체 효과 평가 왜곡
* 논문 구조상 **데이터 누수, 약한 비교 기준, 체리피킹, 미보고** 등 체계적 오차나 편향이 반복적으로 발생함
* 평가자와 이해관계자가 동일한 공동체 내에 있어, **성과 평가는 이익에 직결되는 이해상충 구조**에서 이루어짐
* 이러한 현상은 과학 내 AI 영향 평가 시, "영양학 논문에서 단일 연구 결과를 무조건 신뢰하지 않는 태도"와 비슷한 **본질적 회의와 비판적 검증 습관** 필요성 전달

결론
--

* AI는 단기적으로는 과학 혁신을 이끄는 **혁명적 도구라기보다, 기존 방식의 점진적·선택적 보완 수단**일 가능성에 무게가 실림
* 연구 생태계의 **구조적 인센티브, 과대평가 및 실패 미보고, 약한 비교 기준 문제**로 인해, AI의 실제 과학적 성과를 평가할 때 항상 비판적·회의적 관점 유지 필요성 강조
* **이상적인 AI 혁신에는 구조적 개혁(도전 과제 출제, 실패 사례 공개, 공정 비교체계 발전 등)이 병행**되어야 한다는 메시지 전달
