# Ironwood - 추론 시대를 위한 최초의 구글 TPU


* Google이 7세대 Tensor Processing Unit(TPU)인 **Ironwood**를 발표함
* Ironwood는 **AI 추론을 위해 특별히 설계된 첫 TPU**이며, 현재까지 가장 강력하고 에너지 효율적인 모델임
* **대형 언어 모델(LLM)** 과 **Mixture of Experts(MoE)** 같은 고성능 AI 모델 실행을 위해 설계됨
* 최대 **9,216개 칩으로 확장** 가능하며, **42.5 엑사플롭스(Exaflops)** 의 연산 성능 제공
* 이는 세계에서 가장 빠른 슈퍼컴퓨터인 El Capitan의 24배 이상 성능임

### Ironwood로 실현되는 추론 시대

* 기존의 AI는 사용자 요청에 응답하는 방식이었다면, Ironwood는 데이터를 **능동적으로 해석하고 통찰을 생성하는 AI** 시대를 위한 기반을 제공함
* 이 추론 시대에는 AI가 **사용자 대신 데이터를 수집하고 분석**해 더 심도 깊은 결과를 도출함
* Ironwood는 이 같은 새로운 AI 요구사항에 대응하기 위해 대규모 **병렬 처리와 고속 데이터 접근** 기능을 갖춤

### Ironwood의 하드웨어 구성 및 성능

* **9,216개 칩으로 구성된 TPU 팟(pod)** 구성 시, **42.5 엑사플롭스** 성능 제공
* **각 칩당 4,614 TFLOPs**의 성능으로, 대규모 LLM 및 MoE 모델 훈련과 추론을 지원함
* **SparseCore** 기능 향상으로 초대형 임베딩 처리를 가속화하며, 금융, 과학 등 다양한 영역으로 적용 가능함
* **Pathways** 소프트웨어를 통해 수만 개의 Ironwood 칩을 효율적으로 관리 가능함

### Ironwood의 주요 기술 특징

* **성능 대 전력 효율** 비율이 이전 세대보다 2배 개선됨
  + **Trillium 대비 약 30배 높은 전력 효율성**
  + 고성능 액체 냉각 기술을 통해 지속적인 고부하 작업에서도 안정적인 성능 유지
* **고대역폭 메모리(HBM)** 용량이 대폭 증가됨
  + **칩당 192GB**, Trillium 대비 6배 확대
  + 대형 모델 및 데이터셋 처리에 유리
* **HBM 메모리 대역폭** 향상
  + 칩당 **7.2 TBps**, Trillium 대비 4.5배 증가
* **Inter-Chip Interconnect (ICI)** 대역폭 개선
  + **1.2 Tbps 양방향**, Trillium 대비 1.5배 향상
  + 칩 간 빠른 통신으로 대규모 분산 훈련과 추론에 적합

### Ironwood의 영향력과 활용 가능성

* Ironwood는 Google Cloud Hypercomputer 아키텍처의 핵심 구성 요소로, 차세대 생성형 AI 요구에 최적화됨
* Gemini 2.5, AlphaFold와 같은 최신 AI 모델도 TPU 기반에서 실행되고 있음
* Google Cloud 고객들은 Ironwood를 통해 **높은 성능, 낮은 지연, 향상된 에너지 효율**로 AI 워크로드를 처리할 수 있음
* 2025년 내 고객 사용 가능 예정이며, AI 연구와 실제 응용에서 새로운 혁신을 이끌 기반이 될 것으로 기대됨
