# HackerNews를 모두 다운로드 받아봤어요


* 작성자는 **해커뉴스의 모든 데이터를 다운로드**하고 이를 **DuckDB로 분석**함
* **20GB에 달하는 전체 아이템(스토리 + 댓글)을 JSON 파일로 저장**, 향후 업데이트도 가능하게 구성함
* DuckDB를 활용해 **‘파이썬’, ‘자바스크립트’, ‘루비’, ‘러스트’ 등의 언급 비율을 주간 단위로 시계열 분석**함
* **SQL 작성에는 LLM을 활용**해 초보자도 쉽게 복잡한 분석을 진행할 수 있었음
* 해당 프로젝트는 공개된 사이트 [hn.unlurker.com](https://hn.unlurker.com)에서 확인 가능하며, **누구나 이 데이터를 분석 기반으로 재활용할 수 있음**

---

전체 해커뉴스 데이터를 긁다
---------------

* `hn.unlurker.com`을 만들며 **Go 언어로 자체 HN API 클라이언트를 개발**, 최신 Go 기능과 린터를 활용한 개인 프로젝트로 출발
* Hacker News의 아이템(HN API에서 스토리와 댓글)을 **0번부터 순차적으로 모두 다운로드**하는 `scan` 명령어 구현
* 다운로드는 수 차례 중단됐지만 **재시작 가능한 구조로 수 시간 만에 약 20GiB JSON 파일 확보**

DuckDB로 텍스트 시계열 분석
------------------

* `grep`으로 간단한 패턴 검색을 하던 중, **분석 툴로 DuckDB를 시도**, 소규모 단일 파일 분석에 최적화된 고속 DB
* JSON 파일을 테이블로 불러오고, **아이템 텍스트 내 언급된 언어들의 비율을 주간 단위로 계산**
* Python, JavaScript, Java, Ruby, Rust 키워드를 포함한 비율을 **12주 이동 평균**으로 시각화할 수 있도록 SQL 작성
* DuckDB의 신규 UI 덕분에 사용이 쉬워졌고, **LLM의 도움으로 SQL도 쉽게 작성 가능**

결과 및 다음 계획
----------

* DuckDB는 이 규모의 데이터 분석에 **탁월한 성능과 사용성을 제공**
* 데이터 확보 완료 후, 작성자는 농담 반 진심 반으로 "**LLM 기반 봇 수백 개를 훈련시켜 해커뉴스를 대체하겠다**"고 언급
* 그러나 실질적인 데이터 수집 및 분석 목적은 달성했으며, **프로젝트는 여기서 마무리**
* 이후 분석은 **누군가 이 데이터를 바탕으로 새로운 인사이트를 도출할 사람의 몫**이라고 밝힘

참고 링크
-----

* [hn.unlurker.com](https://hn.unlurker.com): 프로젝트 결과물 공개 사이트
* [GitHub - unlurker](https://github.com/jasonthorsness/unlurker): HN API 클라이언트
* [DuckDB 공식 사이트](https://duckdb.org/): 사용된 데이터베이스 툴
