# AI가 Microsoft 개발자들을 미치게 만드는 걸 보는 게 새로운 취미가 되었어요


* GitHub과 Microsoft가 **GitHub Copilot Agent의 퍼블릭 프리뷰**를 발표하면서, .NET Runtime 저장소에 실제로 이 에이전트가 **PR을 자동 생성**하는 테스트가 진행됨
* 그러나 이 PR들은 **부실하거나 불필요한 수정**을 포함하고 있어 리뷰어들이 곤욕을 치르고 있으며, Reddit 사용자들은 이를 **웃픈 풍경**으로 받아들이는 중
* 예시 PR:
  + [PR #115762](https://github.com/dotnet/runtime/pull/115762) – "string.Concat" 호출에서 Null 체크가 이미 되어 있는 코드에 또 불필요하게 체크 추가
  + [PR #115743](https://github.com/dotnet/runtime/pull/115743) – 아무 영향 없는 조건문 리팩토링을 제안
  + [PR #115733](https://github.com/dotnet/runtime/pull/115733), [PR #115732](https://github.com/dotnet/runtime/pull/115732) 등도 비슷한 맥락
* 작성자는 "이게 업계의 미래라면 나는 내릴 준비가 됐다"며 **AI 도입에 대한 피로감과 회의감**을 드러냄
* 하지만 동시에 "리뷰를 맡은 직원들에게는 연민을 느낀다"고 강조하며, 이 상황은 **위에서 내려온 Copilot 도입 지시에 따른 부담**일 가능성이 높다고 덧붙임
  > 제 "schadenfreude(행복감)"는 AI 과대광고를 부추기는 마이크로소프트 경영진을 향한 것입니다. 개발자들을 존중해 주시기 바랍니다.
  >
  > + **schadenfreude**는 독일어에서 유래한 단어로 직역하면 “해로움에서 오는 기쁨”. 즉, "타인의 불운에서 느끼는 몰래 기분 좋은 감정"

주요 댓글들 요약
---------

### 1. **AI가 작성한 PR은 부정확하고, 맥락을 이해하지 못한 채 단순히 '추측'만 반복**

* 실제 PR 코드가 무엇을 하는지 이해 없이 변경을 제안함
* 반복적인 오류 수정 → 여전히 잘못된 코드 → 또 다른 오류 수정…의 **끝없는 루프**
* “수정했어요” → “아직도 틀렸어” → “이번엔 정말 고쳤어요”… 이 과정이 **Junior Dev 패턴** 같다는 의견도

### 2. **복잡한 문제 해결엔 오히려 더 많은 시간 소요**

* 단순한 수정에는 도움이 되지만, **진짜 시간 아끼고 싶은 복잡한 문제엔 쓸모없음**
* 문제 이해 → Copilot 이해 → 비교 → 확인 → 수동 조치 필요
* 실제로는 **내가 직접 해결하는 게 빠름**

### 3. **기업 리더들의 'AI 만능주의'가 개발자를 소외시키고 있음**

* "Copilot을 쓰면 뒤처지지 않는다"는 메시지는 **실무 개발자와 괴리**
* PR 리뷰 시간은 길어지고, 책임은 개발자에게 전가
* Copilot이 만든 코드로 학습된 AI가 다시 코드 품질을 악화시키는 **'AI의 AI를 위한 학습 루프'** 우려

### 4. **AI는 확신에 찬 ‘틀린 답’을 내놓을 뿐, '이게 맞다'는 확신은 없음**

* 틀렸다는 피드백에도 “수정했습니다!” → 더 이상한 수정 제안
* "이건 괜찮은 코드야, 고칠 필요 없어"라는 판단은 하지 않음
* 이는 법적 책임 회피를 위한 설계일 수 있다는 지적도

### 5. **지속적인 AI 도입 강요로 개발자 경험은 피폐해지고 있음**

* 관리자 지시나 실적 평가 때문에 AI 도입 실험이 이어짐
* 개발자들은 자신이 AI의 베이비시터가 된 듯한 피로감을 호소
* 이 흐름이 이어지면 "개발자들이 AI에 지쳐 업계를 떠날 것"이라는 비관적 전망도

주요 문장들
------

* **“AI는 잘못된 추측을 반복하면서도 자기 주장을 확신하는 인턴 같아요”**
* **“Copilot 코드 리뷰하는 데 시간 쓰느니, 내가 새로 짜는 게 낫다”**
* **“이건 개발자가 기계를 돕는 'reverse centaurs' 상태”**
  + Cory Doctorow가 쓴 단어로, "우리는 기계의 도움을 받는 인간이 아니라, 기계를 돕도록 강요받는 인간이라는 것"
* **“Copilot은 개발자가 엉터리 반창고를 붙이는 것과 같은데, 다만 자동화 되어있어서 수천개의 부담스러운 반창고가 됨”**
* **“LLM은 ‘잘못될 수 있지만, 불확실하진 않아’가 기본값인 듯”**
