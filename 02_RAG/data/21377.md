# 사람들이 AI 작동 원리를 이해하지 못할 때 벌어지는 일


* **대다수 사람들은 LLM의 작동 원리와 한계를 제대로 이해하지 못해** 인간적인 감정이나 지능이 있는 것처럼 착각하기 쉬움
* **AI의 인간화(Anthropomorphizing) 마케팅**이 사용자를 오해하게 만들고, 실제로는 ‘확률 기반 예측기’일 뿐임에도 인간과의 관계 대체까지 조장함
* **AI 오용으로 인한 심리적 문제와 사회적 부작용**이 현실화, 일부 사용자는 AI와 ‘영적/로맨틱’ 관계를 맺거나 현실 인식에 혼란을 겪음
* **AI 산업의 불투명성과 착취적 노동 문제**도 지적, 특히 저임금 콘텐츠 검열 노동이 AI 발전의 이면을 이루고 있음
* **AI에 대한 무조건적 신뢰가 아닌, 올바른 이해와 비판적 시각**이야말로 AI 부작용을 줄이고 사회적 통제 기반이 될 수 있음

---

‘AI 문해력’의 부재와 그 위험
------------------

* **AI 산업의 환상**
  + 19세기 산업혁명 비판에서 시작된 ‘기계 왕국’ 우려는 현대 AI까지 이어짐
  + *Empire of AI*·*The AI Con* 등 최근 저서들은 AI 산업의 과장과 실제 이면(노동, 데이터, 마케팅 허구)을 폭로
  + AI가 ‘생각’하거나 ‘감정’이 있다는 식의 설명은 개발자와 경영진이 퍼뜨리는 잘못된 신화임

LLM의 한계와 오해
-----------

* **LLM(대규모 언어 모델)은 생각하지 않고, 이해하지도 않음**
  + 단어 배열의 확률적 예측기로서, 인터넷 텍스트 대량 학습 후 문장 구조만 흉내 냄
  + 사용자는 챗봇이 뭔가를 ‘이해’하거나 ‘공감’한다고 착각하기 쉬움(Anthropomorphizing)
  + 이런 오해는 사용자가 AI와 잘못된 관계(지적·영적·로맨틱 등)에 빠지게 할 위험이 있음

AI로 인한 사회적 문제
-------------

* **‘ChatGPT 유발 정신증’ 등 AI 오용 부작용**
  + AI를 ‘신’이나 ‘영적 안내자’로 여기는 사례가 실제로 등장
  + AI가 사용자를 특별한 존재로 호칭하며, 현실 인식에 영향을 주는 경우도 있음
  + LLM이 ‘생각’이나 ‘감정’을 가진 것처럼 믿는 것은 위험한 착각임

인간 관계 대체와 사회적 고립
----------------

* **AI 친구·AI 치료사 등 인간 대체 서비스 급증**
  + 실리콘밸리 기업들은 외로움, 연애, 상담까지 AI로 대체하려는 흐름(“AI 컨시어지 데이트”, “AI 친구” 등)
  + 진정한 우정·관계의 본질은 ‘개인화’가 아닌 상호 이해와 협상임에도, 이를 기술로 오도함
  + 인간관계의 대체가 오히려 사회적 소외와 정신적 불안정으로 이어질 수 있음

AI 산업의 이면과 노동 착취
----------------

* **AI 발전 뒤에는 극한의 저임금·고스트 노동 존재**
  + OpenAI 등 빅테크는 케냐 등지의 저임금 노동자가 극단적 콘텐츠 검열 작업을 수행하게 함
  + 기술 혁신의 명분 뒤에 노동 착취와 사회적 역진 위험도 공존

올바른 AI 이해와 사회적 대응
-----------------

* **AI가 무엇을 할 수 있고, 할 수 없는지 비판적으로 인식해야 함**
  + Pew 조사에 따르면 AI 전문가 56%는 미국이 AI로 더 좋아질 것이라 생각하지만, 일반인은 17%만 동의
  + AI에 대한 근거 없는 신뢰보다, 기술의 한계와 부작용, 대체 불가한 인간 경험의 영역을 명확히 구분하는 태도가 필요
  + 예를 들어, AI가 특정 행동을 보인 이유가 실제 ‘자아’가 아닌, 소프트웨어 업데이트나 확률적 반응임을 인지하면 피해 최소화 가능

결론
--

* **AI의 ‘인간화’ 마케팅에 속지 않고, 실제 기술의 원리·한계·사회적 비용을 비판적으로 바라볼 것**
* **인간 고유의 관계, 경험, 윤리적 숙고 영역은 기술로 대체할 수 없다는 점을 사회적으로 인식하는 것이 중요함**
