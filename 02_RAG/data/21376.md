# LLM은 정말 저렴하다


* **대다수 사람들이 LLM(대규모 언어 모델) 사용 비용을 과대평가하는 경향**이 있으나, 실제로는 빠르게 저렴해져서 웹 검색보다도 저렴한 수준에 도달
  + 초기 생성형 AI 열풍 당시에는 추론 비용이 높았으나, **지난 2년간 비용이 1000배 가까이 감소**
* **LLM API의 실제 단가를 웹 검색 API와 직접 비교**하면, 저가형 LLM 모델은 심지어 최저가 검색 API보다도 10배 이상 저렴하며, 중간 가격대 모델도 상당히 경쟁력 있는 가격 구조임
* **모델 운영사들이 API 가격을 무리하게 보조하고 있다는 근거는 희박**하며, 실제로 GPU 비용 기준 80%에 달하는 높은 마진을 기록하는 사례도 있음
* **OpenAI 등 주요 AI 기업들이 적자를 내는 이유는 비용 때문이 아니라 낮은 수익화 정책 때문**이며, 이용자당 월 1달러만 받아도 흑자 전환이 가능한 구조임
* **향후 비용 부담의 중심은 LLM 자체가 아니라, 외부 백엔드 서비스(예: 각종 데이터 제공처)로 옮겨갈 전망**임. LLM 실행은 점점 더 저렴해지고, 비즈니스 모델 역시 충분히 성립 가능함

---

LLM의 비용 오해와 현실
--------------

* 많은 사람들이 **ChatGPT와 같은 LLM의 운영 비용이 매우 비싸다**고 오해하고 있음
* 이로 인해 AI 업체의 사업성이 불투명하다거나, 소비자용 AI 서비스의 수익화에 불리하다는 오분석이 반복됨
* **LLM은 아직도 비싸다는 건 인식의 오류**
  + AI 붐 초기에는 추론(inference) 비용이 매우 높았으나, 최근 2년간 비용이 1000배 가까이 감소
  + 많은 논의가 과거 기준의 비용 구조를 기반으로 잘못된 전망을 하고 있음
* 흔히 사용되는 **"1백만 토큰당 가격 모델"** 은 직관적으로 이해하기 어려움

웹 검색 API와 LLM API 가격 비교
-----------------------

* **대표적 웹 검색 API 요금**
  + Google Search: $35/1000회
  + Bing Search: $15/1000회
  + Brave Search: $5~9/1000회, 단가가 높아질수록 오히려 가격이 오르는 구조
  + 전체적으로 웹 검색 API는 저렴하진 않으며, 서비스 질이 좋은 쪽이 더 비쌈
* **LLM API(1k 토큰 기준) 요금**
  + Gemma 3 27B: $0.20
  + Gemini 2.0 Flash: $0.40
  + GPT-4.1 nano: $0.40
  + Deepseek V3: $1.10
  + GPT-4.1: $8.00 등
  + 검색과 비교 가능한 방식으로 LLM 단가 산정 필요: 한 질의당 토큰 출력 개수 + 토큰당 가격
  + **500~1000토큰이 평균 쿼리당 소비량으로, 직접적 비교 가능**
* **저가 LLM 모델은 최저가 검색 API 대비 10~25배 저렴**
  + 품질 중간대 LLM도 동일 구간의 검색보다 훨씬 낮은 비용
  + 배치 단위, 비피크 시간 할인 등 다양한 추가 할인 조건 고려시 더 저렴해짐

비용이 저렴한 진짜 이유
-------------

* **모델 제공사들의 API 단가 보조 의혹은 근거 약함**
  + API 시장점유율 확대의 유인도 약하며, 다수 타사 제공 API 가격도 경쟁적으로 형성됨
  + Deepseek의 실측 자료에 따르면 GPU 기준 마진이 80%에 달함
* **훈련(Training) 비용과 추론(Inference) 비용**
  + 대규모 추론 트래픽에 의해 훈련비용이 효과적으로 분산(Amortize)되고 있음
  + 오히려 서드파티 백엔드 서비스 이용 시 발생하는 비용이 문제로 부각될 가능성

“LLM API는 적자일 것” 주장의 반박
-----------------------

* **OpenAI 등 대형 사업자 적자는 낮은 수익화 전략의 결과**
  + 월 1달러 수준의 수익화만 해도 흑자 전환 가능
  + 무료 사용자 트래픽을 활용한 데이터 수집 목적 등도 존재
* **향후 진짜 비용 이슈는 LLM이 아니라 외부 백엔드**
  + 예: AI 에이전트가 티켓 예매 등 외부 API를 호출할 경우, 실제로는 서드파티의 비용 부담이 커질 수 있음
  + 서비스 사업자들은 크롤링 차단, 모바일 전환, 로그인 강화 등으로 대응할 전망

왜 중요한가
------

* 많은 미래 예측이 **LLM이 비싸다**는 잘못된 전제에 기반해 이루어지고 있음
* 실제로는 비용 하락과 수요 증대가 동시에 발생, 향후 가격은 더 하락하며 시장 활성화 예상
* Frontier AI 기업들은 수익화보다 시장 선점에 초점을 두며, 실제로 LLM 서비스 단가가 특히 낮음
* 진짜 비용 문제는 LLM 자체가 아니라 후방의 **외부 연동 서비스(예: 티켓팅 사이트 등)** 에 있음
* 이러한 외부 서비스들이 수익을 얻지 못하는 구조에서, 향후 AI와 백엔드 서비스 간 새로운 수익모델 또는 기술적 대립 가능성 존재

결론 및 전망
-------

* **LLM의 추론 비용 자체는 더 이상 AI 비즈니스의 본질적 제약이 아님**
  + 저렴한 실행 비용과 다양한 수익화 옵션(예: 광고, 구독 등)으로 충분히 사업적 가능성 보유
  + 앞으로는 LLM이 아닌, AI가 활용하는 외부 데이터 제공처의 비용·인프라 문제가 주요 과제가 될 것
* **시장·기술 변화에 맞춘 현실적 비용 인식과 비즈니스 전략 전환이 필요함**
