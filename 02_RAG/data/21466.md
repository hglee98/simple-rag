# Rust에서 상호작용형 Datalog 엔진 만들기


* **Datalog 논리 프로그래밍과 Rust의 효율성을 결합**하여, 심플하면서도 사용성이 높고, 성능까지 고려한 상호작용형 Datalog 엔진 개발 과정을 상세하게 공유함
* **직관적 CLI 환경에서 규칙(rule)과 사실(fact)을 실시간으로 추가/확장 가능**, 대량 데이터 적재, 동적 규칙 입력 및 빠른 쿼리 성능까지 경험할 수 있음
* **파싱(Parsing), 데이터 표현(Representation), 규칙 평가(Planning/Evaluation)** 를 단계별로 Rust 코드와 함께 설명해 실제 구현 방법을 익힐 수 있음
* **최적화되지 않은 단순 구현부터 시작해 점진적으로 성능과 구조를 개선**하는 과정을 통해, 데이터 병렬처리/조인 최적화 등 고급 로직도 학습할 수 있음
* **대규모 데이터셋 기반 프로그램 분석(Nullability, Aliasing 등)** 사례를 실제로 실행하며 성능 및 메모리 이슈, 쿼리 최적화, join-plan 개선 노하우를 공유함

---

도입: Rust에서 Datalog 논리 프로그래밍 실험
------------------------------

* Memorial Day 기간, Minnowbrook 컨퍼런스에서 다양한 논리 프로그래밍(Datalog 등) 실습과 토론 진행
* 기존 Datalog 도구들(Soufflé, ctdal 등)은 실제 사용/확장성/성능 측면에서 한계 발견, 실용적 도구 필요성 부각
* 필자는 직접 Rust로 심플/사용성/성능을 모두 만족하는 Datalog 인터프리터(datatoad)를 구현하기로 결정
* 프로젝트 목표: CLI에서 대용량 데이터를 빠르게 적재하고, 동적으로 규칙 추가/수정하며, 실시간 결과 확인 및 쿼리 성능도 확보

Datalog 기본 개념
-------------

* **Datalog**는 규칙(Head :- Body) 형태의 논리문을 기반으로, 주어진 fact와 rule로부터 모든 도출 가능한 사실을 자동 유도
* 규칙(예: `tri(a, b, c) :- edge(a, b), edge(b, c), edge(a, c)`)은 변수/리터럴로 이루어짐
* **fact**는 조건 없는 참인 값(예: `edge(1, 2) :- .`)
* Datalog의 강점: 규칙 추가 시 추론 가능한 정보 집합이 늘어나고(단조성), 규칙/사실 순서에 상관없이 동일 결과를 도출(수렴성)
* Rust로는 규칙과 fact를 Atom/Rule/Term 구조체로 표현, relation 별로 fact 집합을 관리함

핵심 구조 설계
--------

### 데이터 표현

* **Fact**는 `Vec<String>`으로, fact 집합은 `BTreeMap<String, Vec<Fact>>` 등으로 초기 설계
* 대용량 데이터 최적화를 위해 columnar(칼럼 지향) 데이터 구조 도입(alloc overhead 최소화)
* **FactContainer**: 정렬/중복제거된 fact 집합, append only 구조
* **FactLSM**: FactContainer를 여러 계층으로 관리하는 LSM(Log-structured merge-tree) 방식, 삽입 및 정렬/병합 효율화
* **FactSet**: fact의 lifecycle(새로 추가, 최근 도출, 안정화된 fact)을 관리하여 중복 계산, 불필요한 메모리 낭비 방지

### 규칙 적용과 추론

* 각 규칙은 JoinPlan(조인 플랜) 생성 → 적절한 컬럼 순서/키 조합을 기반으로 merge join 방식으로 추론
* **merge join**: body atom별로 key 컬럼 정렬 후, 조인키가 일치하는 경우에만 새로운 fact 도출(성능 극대화)
* FactSet의 stable/recent/to\_add 구조를 활용해, 이미 도출된 fact와 신규 fact를 분리하여 불필요한 재계산 방지(차분 평가)
* `.update()` 루프: 신규 fact 도출이 멈출 때까지 모든 규칙 반복 적용, fixpoint 도달 시까지 추론 반복

### 파서 구현

* Soufflé 스타일 문법(`?var`, `:-`, `.`, `,` 등) 지원, Rust로 직접 토크나이저/파서 작성
* 오류 발생 시 안전하게 None 반환, 실험적 환경에 맞는 심플 파서 설계

성능 최적화와 실제 분석 예시
----------------

### Nullability 분석(Reachability)

* 대용량 데이터셋(예: httpd\_df)에서 값 복사/이동 경로 추적을 위한 Datalog 규칙 정의 및 성능 측정
* 다양한 규칙 작성 패턴에 따라 성능 차이 극심(변수 바인딩/컬럼 순서/조인 플랜에 따른 temp relation 발생 등)
* 데이터 초기 형태/조인 전략에 따라 실행 시간, 메모리 사용량이 수십 배 차이 발생, 쿼리 최적화의 중요성 직접 체험
* 최적화 적용 시 기존 C++ 기반 도구(Graspan 등) 대비 10~80배 이상 성능 개선 확인

### Aliasing 분석(Points-to)

* aliasing/포인터 추적 분석을 위한 복잡한 Datalog 패턴 구현, 논문(Graspan, Zheng-Rugina 등)과 동일한 쿼리 실행
* **Datalog 규칙 내 반복(`^*`), 옵션(`^?`), 전치(`^T`) 연산을 명시적 재귀/union으로 확장**
* 중간 결과(relation alias, temp join 등)의 네이밍/재사용 설계에 따라, 전체 쿼리 플랜의 효율 및 자원 소모 대폭 차이
* 쿼리 플랜 최적화 없이 큰 중간 결과를 생성하면, 성능 저하와 메모리 폭증을 초래(예: V relation)
* 필요한 결과만 산출하는 "demand-driven" 방식(매직셋 변환) 논의, 실제 쿼리 플랜 변형 및 성능 개선 가능성 제시

Rust로 직접 실험하며 얻은 교훈
-------------------

* **Datalog 엔진 성능의 핵심은 데이터 표현(칼럼ar/LSM), 차분 추론, join 플랜 최적화에 있음**
* 단순히 규칙을 기계적으로 작성하면, 불필요한 중간 데이터 생성과 리소스 낭비로 이어짐(최적화 필요)
* Rust로 직접 실험하며, 실전 데이터셋에서 수백만/수천만 row의 fact를 효율적으로 관리하고, 확장성과 추론 속도를 동시에 달성할 수 있음
* CLI 환경에서 대규모 데이터 적재, 실시간 규칙 추가, 결과 확인까지 손쉽게 실험 가능
* query optimizer의 역할, bushy-tree join(중간 결과 활용), 필요 없는 관계의 생성을 피하는 습관 등, 실제 Datalog 작성 및 운영에 큰 시사점

앞으로의 확장 과제
----------

* 디스크 스필, 다중 워커/프로세스 분산 확장, 스트리밍 조인, 커스텀 컴파일 최적화 등 연구 과제 남아 있음
* 대규모 프로그램 분석, 그래프/관계 추론, 정적분석, 데이터 흐름 추적 등 실전 분야에서 Rust Datalog의 활용 가능성 높음
