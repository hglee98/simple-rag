# Microsoft, CPU에서 실행가능한 초고효율 AI 모델 BitNet 개발


* Microsoft 연구진이 **BitNet b1.58 2B4T**라는 **초효율적인 AI 모델**을 개발했음
* **1비트 양자화**를 통해 **높은 속도와 낮은 메모리 사용량 달성**하여 **CPU**에서도 실행 가능하며 **MIT 라이선스**로 공개됨
* Apple M2 같은 CPU에서도 실행 가능하며 GPU 없이 작동함
* **20억 개의 파라미터**를 가진 BitNet b1.58 2B4T는 **Meta, Google, Alibaba 모델**보다 성능이 뛰어남
* 다만, **Microsoft의 bitnet.cpp 프레임워크**를 사용해야 하며, **GPU**와의 호환성 문제는 여전히 존재함

---

Microsoft의 초경량 1비트 AI 모델 BitNet b1.58 2B4T
------------------------------------------

### 초경량 모델 BitNet의 개념

* **BitNet**은 **1비트 양자화**를 적용한 AI 모델로, **-1, 0, 1** 세 가지 값만을 사용하여 파라미터를 표현함
* 기존의 양자화 모델은 일반적으로 8비트 또는 4비트로 표현되지만, BitNet은 1비트만 사용해 **압도적인 메모리 효율성**을 가짐
* 이 방식은 **저사양 하드웨어**, 특히 **GPU가 없는 CPU 환경**에서 큰 이점을 가짐

### BitNet b1.58 2B4T의 특징

* **파라미터 수: 20억 개**
* **학습 데이터: 4조 토큰** (약 3,300만 권의 책 분량)
* MIT 라이선스로 **오픈소스 공개**됨
* **Apple M2 CPU와 같은 범용 CPU에서도 작동 가능**

### 성능 비교와 벤치마크 결과

* BitNet b1.58 2B4T는 다음 모델들보다 일부 벤치마크에서 우수한 성능을 보임:
  + **Meta Llama 3.2 1B**
  + **Google Gemma 3 1B**
  + **Alibaba Qwen 2.5 1.5B**
* 사용된 주요 벤치마크:
  + **GSM8K**: 초등학교 수준 수학 문제 평가
  + **PIQA**: 물리적 상식 추론 능력 평가
* **일부 테스트에서 최대 2배 빠른 속도**, **메모리 사용량은 현저히 적음**

### 제한 사항 및 호환성 문제

* BitNet의 성능은 **Microsoft의 전용 프레임워크인 `bitnet.cpp`** 에 의존함
* `bitnet.cpp`는 현재 **특정 CPU만 지원**, **GPU는 미지원**
* 이로 인해 **AI 인프라 표준인 GPU 환경과의 호환성 부족**이 단점으로 지적됨
