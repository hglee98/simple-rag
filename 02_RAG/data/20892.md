# 애플의 FastVLM - 비전 언어 모델을 위한 효율적인 비전 인코딩


* 애플이 CVPR 2025에 발표한 "FastVLM: Efficient Vision Encoding for Vision Language Models"의 공식 Repo
* FastViTHD는 **토큰 수 감소와 고해상도 이미지의 인코딩 시간 단축** 성능을 보임
* 가장 작은 모델은 **LLaVA-OneVision-0.5B**보다 85배 빠른 결과와 3.4배 작은 인코더 크기를 달성함
* 대형 모델은 **Cambrian-1-8B**보다 탁월한 성능과 7.9배 빠른 속도를 보임
* **iPhone 등 모바일 기기에서 동작하는 데모 앱**이 제공됨

---

FastVLM 프로젝트의 의의와 장점
--------------------

* FastVLM은 **비전 언어 모델**(Vision Language Model, VLM)을 위한 공식 구현 오픈소스임
* 기존 비전 인코더 대비 **속도와 효율성** 면에서 탁월한 이점을 제공함
* 여러 하드웨어, 특히 **Apple Silicon 및 모바일 환경**에서 활용도가 높음
* 다양한 크기 및 성능의 프리트레인 모델을 직접 선택해 사용할 수 있음
* 타 프로젝트 대비 작은 모델 사이즈로 **최적화된 실시간 응답**과 적은 하드웨어 자원을 보장함

주요 특징
-----

* **FastViTHD**는 하이브리드 구조의 **혁신적인 비전 인코더**로, 출력 토큰 개수를 줄여 고해상도 이미지 인코딩 시간을 크게 단축함
* 가장 작은 FastVLM-0.5B 모델은 **LLaVA-OneVision-0.5B**보다 85배 빠른 TTFT(최초 토큰 생성 시간) 및 3.4배 작은 인코더 크기를 가짐
* Qwen2-7B LLM과 결합된 대형 FastVLM-7B 모델은 **Cambrian-1-8B** 등 최근 SOTA와 비교 시 7.9배 빠른 TTFT에 단일 이미지 인코더로 우수한 성능을 보임
* 실제 모바일 환경(iOS)에서 동작하는 **데모 앱**까지 함께 제공되어 기술 활용도를 즉시 검증 가능함

모델 정보 (Model Zoo)
-----------------

* 다양한 크기의 FastVLM 모델(FastVLM-0.5B, FastVLM-1.5B, FastVLM-7B)이 2단계와 3단계 버전으로 제공됨
* 각 모델별로 **PyTorch 체크포인트** 파일을 공식적으로 제공함
* 사용자는 공식 제공되는 명령어를 활용해 여러 모델을 `checkpoints` 디렉터리에 일괄 다운로드할 수 있음

활용 예시 (Usage Example)
---------------------

* 이미 훈련된 PyTorch 체크포인트를 **predict.py** 스크립트로 쉽고 빠르게 추론 테스트 가능함
* 예시 커맨드를 통해 이미지를 입력하고 프롬프트(질문)를 던지면, 해당 이미지에 대한 묘사 혹은 질문의 답을 얻을 수 있음

Apple Silicon 및 모바일 기기 지원
-------------------------

* Apple Silicon에서의 **추론**을 위해 별도의 모델 내보내기 및 양자화 과정을 설명하는 가이드가 제공됨
* Apple Silicon에 **직접 최적화된 버전의 체크포인트 파일**이 공식적으로 배포됨
* iPhone, iPad, Mac 등에서 바로 사용할 수 있는 앱 개발 가이드 및 소스 코드가 `/app` 폴더에 안내됨

추가 정보 및 오픈소스 안내
---------------

* FastVLM 논문의 공식 arXiv 링크와 CVPR 2025 학회 논문 인용 양식 제공됨
* 코드베이스는 다양한 오픈소스 프로젝트에 기반하고 있으며, 기여 내역과 라이선스 정보가 별도 안내되어 있음
* 모델 및 코드 활용 전 반드시 **라이선스(라이선스 파일 및 모델 라이선스)** 를 확인해야 함
